<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pepe.tracking.Convolution API documentation</title>
<meta name="description" content="Particle position tracking via convolution." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pepe.tracking.Convolution</code></h1>
</header>
<section id="section-intro">
<p>Particle position tracking via convolution.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Particle position tracking via convolution.
&#34;&#34;&#34;
import numpy as np
import cv2
import matplotlib.pyplot as plt

import numba
from scipy.fft import fft2, ifft2

from pepe.preprocess import circularMask, rectMask
from pepe.topology import findPeaks2D
from pepe.utils import lorentzian
from pepe.analysis import adjacencyMatrix

from lmfit import minimize, Parameters, fit_report

def convCircle(singleChannelFrame, radius, radiusTolerance=None, offscreenParticles=False, kernelBlurKernel=3, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, peakDownsample=10, minPeakPrevalence=.1, intensitySoftmax=1.2, intensitySoftmin=.1, invert=False, allowOverlap=True, fitPeaks=True, debug=False):
    &#34;&#34;&#34;
    Perform convolution circle detection on the provided image.

    A brief description of the technique is described below; for
    a more comprehensive discussion, see [1].

    The convolution method identifies circles in an image by convolving
    a kernel (representing what a particle should look like) with the
    image within which you would like to detect circles. This essentially
    finds the likelihood of any particle location being the center for
    such an object. By performing peak detection on this 2D quantity,
    we can identify the most likely places for particles to be.

    While this technique can be used for non-circular objects, this 
    implementation makes use of several simplifications/approximations
    that make it suitable only for radially symmetric objects.

    Tends to give more accurate and consistent results than the Hough
    technique (see `pepe.tracking.houghCircle()`), though evaluation
    times can be longer. When the radius of the circle is not well known
    (with no initial guess), the Hough method should be used. That being said,
    this implementation can fine tune the provided radius, but this requires
    the provided value to be reasonably close to the actual value (within 
    ~10 pixels is ideal).

    The ability to get subpixel precision by interpolating/fitting curves to the
    convolution is currently WIP, and currently the method can, at best, give results
    accurate to within a single pixel.

    
    Parameters
    ----------
 
    singleChannelFrame : np.uint8[H, W]
        The frame to perform circle detection on. Should not include multiple
        color channels. If it does, the channels will be averaged to form a
        grayscale image.

    radius : float or [float, float]
        The radius to look for, or min and max radii to constrain the circle
        detection. If a single value is provided, a range will be constructed
        around that value with the `radiusTolerance` parameter.

        Note that this method is more sensitive to the initial guess of radius
        than `pepe.tracking.houghCircle()`. Ideally, the radius should be within
        ~10 pixels of the true radius (or a range of radii should only be ~15 pixels wide).

        NOTE: Varying the radius is still under development, and likely does not work that great.

    radiusTolerance : float or None
        The half-width of the range of radii that will be tested for detecting particles.
        ie. the range will be calculated as `[radius + radiusTolerance, radius - radiusTolerance]`.

        If set to `None`, radius will be fixed at whatever value is provided via `radius` argument.

        NOTE: Varying the radius is still under development, and likely does not work that great.

    offscreenParticles : bool
        Whether or not the algorithm should look for particles whose centers are outside of
        the image domain (but some parts of the particles still show up in the image).

        This expands the padding provided to the fft/ifft calculations, so as to avoid cutting
        off what might be a potential particle. As a result, a value of True will increase computation times.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    peakDownsample : int
        The factor by which to downsample the image when performing the initial peak
        detection. The final peak detection will always be performed at the original
        resolution, so this should not affect the accuracy of the detected circles,
        though it is possible that some particles in a densely packed system may
        not be detected. False

        Set to `1` or `None` to perform no downsampling, though this is not recommended,
        as the peak finding algorithm is O(N) where N is the total number of grid points.

    minPeakPrevalence : float
        The minimum prevalence (or persistence) of peaks that will be considered as
        particles. Should be a float in the range `[0, 1.]`, representing the percent
        of the total intensity data range that must be spanned by a feature.

        See `pepe.topology.findPeaks2D()` for more information.

    fitPeaks : bool
        Whether or not to fit each peak in the convolution with a lorentzian
        form and use that center as the location of the particle (instead of
        the simple maximum point).

    intensitySoftmax : float
        Value at which to cap the intensity values in the image, calculated as
        this value multipled by the mean of the image.

        Set to `None` to skip this preprocessing step.

    intensitySoftmin : float
        Zero-out all values that have an intensity below this factor times the mean of
        the image.

        Set to `None` to skip this preprocessing step.

    allowOverlap : bool
        Whether or not to allow detections of particles that overlap. If set to
        False, then the particle with the stronger signature will be kept
        
    debug : bool
        Whether or not to draw debug information on a plot. 

    invert : bool
        If particles appear dark on a bright background, this will invert the
        image (and convolution peak finding will go from looking for maxima
        to looking for minima).
   
    Returns
    -------

    centers : np.ndarray[N,2]
        The detected circles&#39; centers.

    radii : np.ndarray[N]
        The detected circles&#39; radii.


    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.63-68.
    CRC Press. https://doi.org/10.1201/b19291

    &#34;&#34;&#34;
    # General housekeeping of arguments, see if we need to parse anything
    if offscreenParticles:
        paddingFactor = 2.
    else:
        paddingFactor = 1.1

    if peakDownsample is None:
        peakDownsample = 1
 
    # Check if we are given a range of radii or just a single value
    possibleRadii = None

    if hasattr(radius, &#39;__iter__&#39;):
        if len(radius) == 2 and radius[0] &lt; radius[1]:
           possibleRadii = np.arange(radius[0], radius[1]+1)
        else:
            raise Exception(f&#39;Invalid radius provided to convCircle()!\n Expected scalar or [min, max], but got {radius}!&#39;)
    elif radiusTolerance is not None:
        # Use the tolerance
        possibleRadii = np.arange(radius - radiusTolerance, radius + radiusTolerance)
    else:
        # Just the single value
        possibleRadii = np.array([radius])

    # Start with just the mean of the possible radii options
    initialRadius = np.mean(possibleRadii)

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = np.copy(singleChannelFrame)
            
    if invert:
        imageArr = np.max(imageArr) - imageArr

    if intensitySoftmax is not None:
        softmax = np.mean(imageArr) * intensitySoftmax
        if not invert:
            imageArr[imageArr &gt;= softmax] = softmax
        #else:
        #    imageArr[255 - imageArr &gt;= softmax] = softmax

    if intensitySoftmin is not None:
        softmin = np.mean(imageArr) * intensitySoftmin
        if not invert:
            imageArr[imageArr &lt;= softmin] = 0
        #else:
        #    imageArr[255 - imageArr &lt;= softmin] = 0

    # Calculate convolution
    convArr = circularKernelFind(imageArr, initialRadius, fftPadding=int(initialRadius*paddingFactor),
                                 outlineOnly=outlineOnly, outlineThickness=outlineThickness,
                                 negativeHalo=negativeHalo, haloThickness=haloThickness,
                                 negativeInside=negativeInside, kernelBlurKernel=kernelBlurKernel, debug=debug)

    if debug:
        plt.show()

    # Downsample data by 5-10x and run peak detection
    downsampledConvArr = cv2.resize(cv2.blur(convArr, (peakDownsample,peakDownsample)), (0,0),
                                    fx=1/peakDownsample, fy=1/peakDownsample, interpolation=cv2.INTER_CUBIC)

    peakPositions, peakPrevalences = findPeaks2D(downsampledConvArr, minPeakPrevalence=minPeakPrevalence)

    lorentzPositions = np.zeros((len(peakPositions), 2))
    cleanedConvArr = np.zeros_like(convArr)

    # We have the option to fit lorentzian peaks to each maximum in the convolution
    # matrix, or we can just take the peak positions as they are
    if fitPeaks:
        def objectiveFunction(params, localImage):
            # Create a small grid across the area
            Y,X = np.ogrid[:localImage.shape[0], :localImage.shape[1]]
            Y += int(params[&#34;center_y&#34;] - localImage.shape[0]/2)
            X += int(params[&#34;center_x&#34;] - localImage.shape[1]/2)

            lorentzArr = lorentzian([Y,X], [params[&#34;center_y&#34;], params[&#34;center_x&#34;]], params[&#34;width&#34;], params[&#34;amp&#34;], params[&#34;offset&#34;])
            
            return np.sum((localImage - lorentzArr)**2)

        # Now we fit an appropriate function to each peak to see if we can refine the center
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            imagePadding = int(np.mean(possibleRadii))
            # Crop out the small area of the image around the peak
            localConv = convArr[max(upsampledPosition[0]-imagePadding, 0):min(upsampledPosition[0]+imagePadding,convArr.shape[0]-1), max(upsampledPosition[1]-imagePadding, 0):min(upsampledPosition[1]+imagePadding, convArr.shape[1]-1)]


            #plt.imshow(localConv)
            #plt.show()
            # Now setup a fit to this function
            params = Parameters()

            params.add(&#39;center_y&#39;, value=localConv.shape[0]/2, vary=True)
            params.add(&#39;center_x&#39;, value=localConv.shape[1]/2, vary=True)
            params.add(&#39;width&#39;, value=imagePadding/2, vary=False)
            params.add(&#39;amp&#39;, value=np.max(localConv)-np.min(localConv), vary=False)
            params.add(&#39;offset&#39;, value=np.min(localConv), vary=False)
        
            result = minimize(objectiveFunction, params, args=[localConv], method=&#39;nelder&#39;, max_nfev=10000)
            
            if result is not None:
                lorentzPositions[i,0] = upsampledPosition[0] - localConv.shape[0]/2 + result.params[&#34;center_y&#34;]
                lorentzPositions[i,1] = upsampledPosition[1] - localConv.shape[1]/2 + result.params[&#34;center_x&#34;]

                Y,X = np.ogrid[:convArr.shape[0], :convArr.shape[1]]
                cleanedConvArr += lorentzian([Y,X], lorentzPositions[i], result.params[&#34;width&#34;], result.params[&#34;amp&#34;], result.params[&#34;offset&#34;])

            else:
                lorentzPositions[i] = upsampledPosition

    else:
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            lorentzPositions[i] = upsampledPosition

    # Look around each peak to find the real peak in the full-resolution image
    # (only if we are actually downsampling)
    refinedPeakPositions = []
    refinedRadii = []

    if peakDownsample &gt; 1:
        # To do this, we use a non-linear optimization scheme
        for i in range(len(peakPositions)):

            costArr = []

            def refineObjectiveFunction(params):
                kernelArr = genCircularKernel(np.array([params[&#34;y&#34;].value, params[&#34;x&#34;].value]), params[&#34;r&#34;].value,
                                              imageArr.shape, kernelBlurKernel, outlineOnly,
                                              outlineThickness, negativeHalo, haloThickness, negativeInside)

                # We are minimizing this function, so we need the cost to be negative
                # (unless we have to invert the image)
                costArr.append((np.sum(kernelArr * imageArr) / np.sum(kernelArr)) * (int(invert)*2 - 1))
                return (np.sum(kernelArr * imageArr) / np.sqrt(np.sum(kernelArr))) * (int(invert)*2 - 1)

            params = Parameters()

            params.add(&#39;y&#39;, value=lorentzPositions[i][0], min=lorentzPositions[i][0]-imageArr.shape[0]*.02, max=lorentzPositions[i][0]+imageArr.shape[0]*.02)
            params.add(&#39;x&#39;, value=lorentzPositions[i][1], min=lorentzPositions[i][1]-imageArr.shape[1]*.02, max=lorentzPositions[i][1]+imageArr.shape[1]*.02)
            # May or may not want to vary the radius
            # Small tolerances on the radius are so that min != max
            params.add(&#39;r&#39;, value=np.mean(possibleRadii), vary=(len(possibleRadii) &gt; 1), max=np.max(possibleRadii)-.01, min=np.min(possibleRadii)+.01)

            result = minimize(refineObjectiveFunction, params, method=&#39;powell&#39;, max_nfev=10000, options={&#34;ftol&#34;: 1e-5, &#34;xtol&#34;: 1e-5})

            #print(fit_report(result))

            if result is not None:
                refinedPeakPositions.append([result.params[&#34;y&#34;].value, result.params[&#34;x&#34;].value])
                refinedRadii.append(result.params[&#34;r&#34;].value)
                
                #if debug:
                #    plt.plot(costArr)
                #    plt.show()

            else:
                refinedPeakPositions.append(lorentzPositions[i])
                refinedRadii.append(np.mean(possibleRadii))

    else:
        refinedPeakPositions = lorentzPositions
        refinedRadii = np.repeat(np.mean(possibleRadii), len(refinedPeakPositions))


    # Now we (optionally) remove overlapping particles
    # TODO: Allow overlap to be a float value, which allows overlaps
    # that do not exceed a certain threshold (eg. that fraction of the radius).
    if not allowOverlap:
        # Calculate the contact matrix
        # negative contact padding because we don&#39;t want to remove particles that are
        # good but just close to each other
        adjMat = adjacencyMatrix(refinedPeakPositions, refinedRadii, contactPadding=-int(np.mean(refinedRadii)/10)) - np.eye(len(refinedPeakPositions))

        # Locate all of the particles that are overlapping
        overlappingParticles = np.array([i for i in range(len(refinedPeakPositions)) if np.sum(adjMat[i,:]) &gt; 0])

        # Now find how good of detections each of these is, and order them from worst to best.
        particleScores = np.zeros(len(overlappingParticles))
        for i in range(len(particleScores)):
            # Need to convert to int16 since we might have negative values
            pMask = genCircularKernel(refinedPeakPositions[i], refinedRadii[i],
                                      singleChannelFrame.shape, kernelBlurKernel, outlineOnly,
                                      outlineThickness, negativeHalo, haloThickness, negativeInside).astype(np.int16)

            if np.sum(pMask) &gt; 0:
                # I square-root the mask sum so that the particles at the edge don&#39;t
                # always win out against actual particles
                # TODO: This still doesn&#39;t give priority to particles on screen;
                # need to figure out a way to do that
                particleScores[i] = np.sum(singleChannelFrame * pMask) / np.sqrt(np.sum(pMask))
            else:
                particleScores[i] = 0 

        # Sort according to worst scores
        order = np.argsort(particleScores)[::-1]
        overlappingParticles = overlappingParticles[order]

        # Now we start removing the particles with the worst scores until we no longer have overlap
        index = 0
        while np.sum(adjMat) &gt; 0:
            adjMat[overlappingParticles[index],:] = 0
            adjMat[:,overlappingParticles[index]] = 0
            refinedPeakPositions[overlappingParticles[index]] = None
            refinedRadii[overlappingParticles[index]] = None

            index += 1

           
        # Now remove all of the None values we put in
        refinedPeakPositions = [rpp for rpp in refinedPeakPositions if rpp is not None]
        refinedRadii = [rr for rr in refinedRadii if rr is not None]


    # Debug option
    if debug:
        fig = plt.figure(figsize=(12,4))

        ax1 = fig.add_subplot(1, 3, 1, projection=&#39;3d&#39;)
        ax1.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), convArr, cmap=plt.cm.jet)
        ax1.set_title(&#39;Convolution&#39;)

        ax2 = fig.add_subplot(1, 3, 2, projection=&#39;3d&#39;)
        ax2.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), cleanedConvArr, cmap=plt.cm.jet)
        ax2.set_title(&#39;Cleaned Convolution&#39;)

        ax3 = fig.add_subplot(1, 3, 3)
        ax3.imshow(singleChannelFrame)
        ax3.set_title(&#39;Detected circles&#39;)
        for i in range(len(refinedPeakPositions)):
            c = plt.Circle(refinedPeakPositions[i][::-1], refinedRadii[i], color=&#39;red&#39;, fill=False, linewidth=1)
            ax3.add_artist(c)

        fig.tight_layout()

    return np.array(refinedPeakPositions), np.array(refinedRadii)


def circularKernelFind(singleChannelFrame, radius, fftPadding, kernelBlurKernel=3, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, paddingValue=None, debug=False):
    &#34;&#34;&#34;
    Calculate the convolution of a circular mask with an image,
    identifying likely locations of circles within the image. Adapted from
    method described in [1].

    To perform the convolution, we take the product of the fft of each the
    kernel and image, and then ifft the result to transform back to real space.
    The only peculiarity is that there can be some issues with the edges of image
    (especially if any circle centers are near the edge/off-screen) so we
    have to take care to properly pad the image and the kernel.

    Note that this method is not intended to be used as the front end for
    circle detection for real data. The method `pepe.tracking.convCircle()`
    makes use of this method to track circles, while also offering many more
    features. It is recommended to use that function unless there is a very
    specific purpose that it does not serve.

    Parameters
    ----------
    singleChannelFrame : np.ndarray[H,W]
        A single-channel image (grayscale or just one channel) within which we
        are looking to identify circular objects.

    radius : float
        The radius of circles to detect in the image.

    fftPadding : int
        The amount of padding to add to each side of the image, to prevent the
        fft from having issues. A good choice is usually 1.5 times the radius,
        though, less padding can be used if circles are not expected to often
        be located near the edges.

    kernelBlurKernel : int
        The kernel size to use to blur the kernel that will be convolved with the image, in
        pixels. A value of 0 or None will use the original kernel.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    paddingValue : [float, `&#39;sigmoid&#39;`, or `None`]
        What value to fill in for the extra padding that is added during the fft/ifft.

        `None` leaves the value at 0.

        `&#39;sigmoid&#39;` will create a smooth-ish transition to 0.

        Any float value will be inserted into every point.

    debug : bool
        Whether or not to plot various quantities of the calculation for inspection
        at the end of the evaluation.

    Returns
    -------

    chiSqr : np.ndarray[H,W]
        The convolution of the kernel with the image. Larger values represent
        higher likelihood that there is a particle centered there.

    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.64-68.
    CRC Press. https://doi.org/10.1201/b19291
    &#34;&#34;&#34;

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = singleChannelFrame

    fftPadding = int(fftPadding)

    # Pad the proper image
    paddedImageArr = np.zeros((int(imageArr.shape[0] + 2*fftPadding), int(imageArr.shape[1] + 2*fftPadding)))
    paddedImageArr[fftPadding:-fftPadding,fftPadding:-fftPadding] = imageArr

    # Both dimensions will always have the same first crop index, but possibly a different second one
    cropBounds = [int(fftPadding + radius), int(-fftPadding + radius), int(-fftPadding + radius)]
    # If the fftpadding and the radius are exactly the same, we get some weird behavior
    # This happens because python can index negative values as that element from the end of
    # the array, but indexing -0 just gives 0, and so it gives you a (0,0) array.
    if cropBounds[1] &gt;= 0:
        cropBounds[1] = None
        cropBounds[2] = None

    # We have a couple options for what values to put in the padding
    if paddingValue is None or paddingValue == 0:
        # Do nothing, and leave the value at 0
        pass

    elif paddingValue == &#39;sigmoid&#39;:
        # Sigmoid gives a smoothish decay from the image to 0 at the boundaries
        # Most of the constants here are just arbitrarily chosen to make things look good
        # Top
        paddedImageArr[:fftPadding] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[fftPadding])[::-1,:] 
        # Bottom
        paddedImageArr[-fftPadding:] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[-fftPadding-1])
        # Left
        paddedImageArr[:,:fftPadding] += np.multiply.outer(paddedImageArr[:,fftPadding], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))[:,::-1]
        # Right
        paddedImageArr[:,-fftPadding:] += np.multiply.outer(paddedImageArr[:,-fftPadding-1], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))

    else:
        # Just put a fixed value in
        paddedImageArr[:fftPadding] = paddingValue
        paddedImageArr[-fftPadding:] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,:fftPadding] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,-fftPadding:] = paddingValue

    center = np.array([radius,radius])
    # To be able to properly convolute the kernel with the image, they have to
    # be the same size, so just just put our kernel into an array the same size
    # as the image (though most entries will just be zero)
    # See function below for more information on generating this kernel
    kernelArr = genCircularKernel(center, radius, paddedImageArr.shape, kernelBlurKernel, outlineOnly,
                                 outlineThickness, negativeHalo, haloThickness, negativeInside)

    # First convolutional term
    convTerm1 = ifft2(fft2(paddedImageArr**2) * fft2(kernelArr))
    # Trim padding
    convTerm1 = convTerm1[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # Second term is pretty easy since we choose our weight function to be our
    # particle mask (and it just has 0s and 1s, so it is equal to it&#39;s square)
    convTerm2 = 2 * ifft2(fft2(paddedImageArr) * fft2(kernelArr))
    # Trim padding
    convTerm2 = convTerm2[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # For the normalization term, we want to sum all parts of the kernel that are
    # on screen (in the original image&#39;s frame) as we translate it across the image.
    originalImageMask = rectMask(paddedImageArr.shape, np.repeat(fftPadding, 2), np.array(imageArr.shape))[:,:,0]
    normalizationTerm = ifft2(fft2(originalImageMask) * fft2(kernelArr))
    # Trim padding
    normalizationTerm = np.real(normalizationTerm[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]])
    # Put everything together
    # Technically there is a +1 here, but that won&#39;t affect any minima, so we don&#39;t really care
    chiSqr = np.real((convTerm1 - convTerm2) / normalizationTerm)
    if np.min(chiSqr) &lt; 0 and np.max(chiSqr) &lt; 0:
        chiSqr = np.abs(chiSqr)

    if debug:
        fig, ax = plt.subplots(1, 4, figsize=(13,4))

        ax[0].imshow(kernelArr)
        ax[0].set_title(&#39;Kernel&#39;)

        ax[1].imshow(paddedImageArr)
        ax[1].set_title(&#39;Padded image&#39;)

        ax[2].imshow(normalizationTerm)
        ax[2].set_title(&#39;Normalization&#39;)

        ax[3].imshow(chiSqr)
        ax[3].set_title(&#39;Real-space convolution (Re)&#39;)

        fig.tight_layout()

    return chiSqr


def genCircularKernel(center, radius, imageShape, kernelBlurKernel=3, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False,):

    kernelArr = circularMask(imageShape, center, radius)[:,:,0].astype(np.float64)

    # If we only want the outline, we subtract another circular mask from the above one
    if outlineOnly:
        # Should be 2 if negative inside is true, 1 otherwise
        negativeInsideFactor = 1 + int(negativeInside)
        if outlineThickness &lt; 1:
            innerRadius = np.ceil((1 - outlineThickness) * radius)
        else:
            innerRadius = radius - outlineThickness
        
        kernelArr = kernelArr - negativeInsideFactor * circularMask(imageShape, center, innerRadius)[:,:,0].astype(np.float64)

        if negativeHalo:
            if haloThickness &lt; 1:
                haloRadius = radius + np.ceil((1 - haloThickness) * radius)
            else:
                haloRadius = radius + haloThickness

            kernelArr = 2*kernelArr - (circularMask(imageShape, center, haloRadius)[:,:,0].astype(np.float64) - circularMask(imageShape, center, radius)[:,:,0].astype(np.float64))

    elif negativeHalo:
        if haloThickness &lt; 1:
            haloRadius = np.ceil((1 + haloThickness) * radius)
        else:
            haloRadius = radius + haloThickness

        kernelArr = 2*kernelArr - circularMask(imageShape, center, haloRadius)[:,:,0].astype(np.float64)

    if kernelBlurKernel is not None and kernelBlurKernel &gt; 0:
        kernelArr = cv2.blur(kernelArr, (kernelBlurKernel,kernelBlurKernel))

    return kernelArr</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pepe.tracking.Convolution.circularKernelFind"><code class="name flex">
<span>def <span class="ident">circularKernelFind</span></span>(<span>singleChannelFrame, radius, fftPadding, kernelBlurKernel=3, outlineOnly=False, outlineThickness=0.05, negativeHalo=False, haloThickness=0.03, negativeInside=False, paddingValue=None, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the convolution of a circular mask with an image,
identifying likely locations of circles within the image. Adapted from
method described in [1].</p>
<p>To perform the convolution, we take the product of the fft of each the
kernel and image, and then ifft the result to transform back to real space.
The only peculiarity is that there can be some issues with the edges of image
(especially if any circle centers are near the edge/off-screen) so we
have to take care to properly pad the image and the kernel.</p>
<p>Note that this method is not intended to be used as the front end for
circle detection for real data. The method <code>pepe.tracking.convCircle()</code>
makes use of this method to track circles, while also offering many more
features. It is recommended to use that function unless there is a very
specific purpose that it does not serve.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>singleChannelFrame</code></strong> :&ensp;<code>np.ndarray[H,W]</code></dt>
<dd>A single-channel image (grayscale or just one channel) within which we
are looking to identify circular objects.</dd>
<dt><strong><code>radius</code></strong> :&ensp;<code>float</code></dt>
<dd>The radius of circles to detect in the image.</dd>
<dt><strong><code>fftPadding</code></strong> :&ensp;<code>int</code></dt>
<dd>The amount of padding to add to each side of the image, to prevent the
fft from having issues. A good choice is usually 1.5 times the radius,
though, less padding can be used if circles are not expected to often
be located near the edges.</dd>
<dt><strong><code>kernelBlurKernel</code></strong> :&ensp;<code>int</code></dt>
<dd>The kernel size to use to blur the kernel that will be convolved with the image, in
pixels. A value of 0 or None will use the original kernel.</dd>
<dt><strong><code>outlineOnly</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether to look for only a particle outline (True), or to look for a filled-in circle (False).</p>
<p>See <code>outlineThickness</code>.</p>
</dd>
<dt><strong><code>outlineThickness</code></strong> :&ensp;<code>float</code> or <code>int</code></dt>
<dd>
<p>Thickness of the particle outline in the kernel; only relevant if <code>outlineOnly=True</code>.</p>
<p>If float, will be taken as fraction of the radius; if integer, will be taken as number
of pixels.</p>
</dd>
<dt><strong><code>negativeHalo</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to surround the particle mask with a region of negative value, which
further promotes identifying distinct objects as grains.</dd>
<dt><strong><code>haloThickness</code></strong> :&ensp;<code>float</code> or <code>int</code></dt>
<dd>
<p>Thickness of the negative halo in the kernel; only relevant if <code>negativeHalo=True</code>.</p>
<p>If float, will be taken as fraction of the radius; if integer, will be taken as number
of pixels.</p>
</dd>
<dt><strong><code>negativeInside</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether to fill the inside of the particle mask with a negative value, which
further promotes identifying outlines of circles.</p>
<p>Has no effect unless <code>outlineOnly=True</code>.</p>
</dd>
<dt><strong><code>paddingValue</code></strong> :&ensp;<code>[float, </code>'sigmoid'<code>,</code> or <code><code>None&lt;/code&gt;]</code></dt>
<dd>
<p>What value to fill in for the extra padding that is added during the fft/ifft.</p>
<p><code>None</code> leaves the value at 0.</p>
<p><code>'sigmoid'</code> will create a smooth-ish transition to 0.</p>
<p>Any float value will be inserted into every point.</p>
</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to plot various quantities of the calculation for inspection
at the end of the evaluation.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>chiSqr</code></strong> :&ensp;<code>np.ndarray[H,W]</code></dt>
<dd>The convolution of the kernel with the image. Larger values represent
higher likelihood that there is a particle centered there.</dd>
</dl>
<h2 id="references">References</h2>
<p>[1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
of Granular Materials. Chapter 2: Experimental Techniques. p.64-68.
CRC Press. <a href="https://doi.org/10.1201/b19291">https://doi.org/10.1201/b19291</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def circularKernelFind(singleChannelFrame, radius, fftPadding, kernelBlurKernel=3, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, paddingValue=None, debug=False):
    &#34;&#34;&#34;
    Calculate the convolution of a circular mask with an image,
    identifying likely locations of circles within the image. Adapted from
    method described in [1].

    To perform the convolution, we take the product of the fft of each the
    kernel and image, and then ifft the result to transform back to real space.
    The only peculiarity is that there can be some issues with the edges of image
    (especially if any circle centers are near the edge/off-screen) so we
    have to take care to properly pad the image and the kernel.

    Note that this method is not intended to be used as the front end for
    circle detection for real data. The method `pepe.tracking.convCircle()`
    makes use of this method to track circles, while also offering many more
    features. It is recommended to use that function unless there is a very
    specific purpose that it does not serve.

    Parameters
    ----------
    singleChannelFrame : np.ndarray[H,W]
        A single-channel image (grayscale or just one channel) within which we
        are looking to identify circular objects.

    radius : float
        The radius of circles to detect in the image.

    fftPadding : int
        The amount of padding to add to each side of the image, to prevent the
        fft from having issues. A good choice is usually 1.5 times the radius,
        though, less padding can be used if circles are not expected to often
        be located near the edges.

    kernelBlurKernel : int
        The kernel size to use to blur the kernel that will be convolved with the image, in
        pixels. A value of 0 or None will use the original kernel.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    paddingValue : [float, `&#39;sigmoid&#39;`, or `None`]
        What value to fill in for the extra padding that is added during the fft/ifft.

        `None` leaves the value at 0.

        `&#39;sigmoid&#39;` will create a smooth-ish transition to 0.

        Any float value will be inserted into every point.

    debug : bool
        Whether or not to plot various quantities of the calculation for inspection
        at the end of the evaluation.

    Returns
    -------

    chiSqr : np.ndarray[H,W]
        The convolution of the kernel with the image. Larger values represent
        higher likelihood that there is a particle centered there.

    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.64-68.
    CRC Press. https://doi.org/10.1201/b19291
    &#34;&#34;&#34;

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = singleChannelFrame

    fftPadding = int(fftPadding)

    # Pad the proper image
    paddedImageArr = np.zeros((int(imageArr.shape[0] + 2*fftPadding), int(imageArr.shape[1] + 2*fftPadding)))
    paddedImageArr[fftPadding:-fftPadding,fftPadding:-fftPadding] = imageArr

    # Both dimensions will always have the same first crop index, but possibly a different second one
    cropBounds = [int(fftPadding + radius), int(-fftPadding + radius), int(-fftPadding + radius)]
    # If the fftpadding and the radius are exactly the same, we get some weird behavior
    # This happens because python can index negative values as that element from the end of
    # the array, but indexing -0 just gives 0, and so it gives you a (0,0) array.
    if cropBounds[1] &gt;= 0:
        cropBounds[1] = None
        cropBounds[2] = None

    # We have a couple options for what values to put in the padding
    if paddingValue is None or paddingValue == 0:
        # Do nothing, and leave the value at 0
        pass

    elif paddingValue == &#39;sigmoid&#39;:
        # Sigmoid gives a smoothish decay from the image to 0 at the boundaries
        # Most of the constants here are just arbitrarily chosen to make things look good
        # Top
        paddedImageArr[:fftPadding] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[fftPadding])[::-1,:] 
        # Bottom
        paddedImageArr[-fftPadding:] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[-fftPadding-1])
        # Left
        paddedImageArr[:,:fftPadding] += np.multiply.outer(paddedImageArr[:,fftPadding], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))[:,::-1]
        # Right
        paddedImageArr[:,-fftPadding:] += np.multiply.outer(paddedImageArr[:,-fftPadding-1], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))

    else:
        # Just put a fixed value in
        paddedImageArr[:fftPadding] = paddingValue
        paddedImageArr[-fftPadding:] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,:fftPadding] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,-fftPadding:] = paddingValue

    center = np.array([radius,radius])
    # To be able to properly convolute the kernel with the image, they have to
    # be the same size, so just just put our kernel into an array the same size
    # as the image (though most entries will just be zero)
    # See function below for more information on generating this kernel
    kernelArr = genCircularKernel(center, radius, paddedImageArr.shape, kernelBlurKernel, outlineOnly,
                                 outlineThickness, negativeHalo, haloThickness, negativeInside)

    # First convolutional term
    convTerm1 = ifft2(fft2(paddedImageArr**2) * fft2(kernelArr))
    # Trim padding
    convTerm1 = convTerm1[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # Second term is pretty easy since we choose our weight function to be our
    # particle mask (and it just has 0s and 1s, so it is equal to it&#39;s square)
    convTerm2 = 2 * ifft2(fft2(paddedImageArr) * fft2(kernelArr))
    # Trim padding
    convTerm2 = convTerm2[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # For the normalization term, we want to sum all parts of the kernel that are
    # on screen (in the original image&#39;s frame) as we translate it across the image.
    originalImageMask = rectMask(paddedImageArr.shape, np.repeat(fftPadding, 2), np.array(imageArr.shape))[:,:,0]
    normalizationTerm = ifft2(fft2(originalImageMask) * fft2(kernelArr))
    # Trim padding
    normalizationTerm = np.real(normalizationTerm[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]])
    # Put everything together
    # Technically there is a +1 here, but that won&#39;t affect any minima, so we don&#39;t really care
    chiSqr = np.real((convTerm1 - convTerm2) / normalizationTerm)
    if np.min(chiSqr) &lt; 0 and np.max(chiSqr) &lt; 0:
        chiSqr = np.abs(chiSqr)

    if debug:
        fig, ax = plt.subplots(1, 4, figsize=(13,4))

        ax[0].imshow(kernelArr)
        ax[0].set_title(&#39;Kernel&#39;)

        ax[1].imshow(paddedImageArr)
        ax[1].set_title(&#39;Padded image&#39;)

        ax[2].imshow(normalizationTerm)
        ax[2].set_title(&#39;Normalization&#39;)

        ax[3].imshow(chiSqr)
        ax[3].set_title(&#39;Real-space convolution (Re)&#39;)

        fig.tight_layout()

    return chiSqr</code></pre>
</details>
</dd>
<dt id="pepe.tracking.Convolution.convCircle"><code class="name flex">
<span>def <span class="ident">convCircle</span></span>(<span>singleChannelFrame, radius, radiusTolerance=None, offscreenParticles=False, kernelBlurKernel=3, outlineOnly=False, outlineThickness=0.05, negativeHalo=False, haloThickness=0.03, negativeInside=False, peakDownsample=10, minPeakPrevalence=0.1, intensitySoftmax=1.2, intensitySoftmin=0.1, invert=False, allowOverlap=True, fitPeaks=True, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform convolution circle detection on the provided image.</p>
<p>A brief description of the technique is described below; for
a more comprehensive discussion, see [1].</p>
<p>The convolution method identifies circles in an image by convolving
a kernel (representing what a particle should look like) with the
image within which you would like to detect circles. This essentially
finds the likelihood of any particle location being the center for
such an object. By performing peak detection on this 2D quantity,
we can identify the most likely places for particles to be.</p>
<p>While this technique can be used for non-circular objects, this
implementation makes use of several simplifications/approximations
that make it suitable only for radially symmetric objects.</p>
<p>Tends to give more accurate and consistent results than the Hough
technique (see <code>pepe.tracking.houghCircle()</code>), though evaluation
times can be longer. When the radius of the circle is not well known
(with no initial guess), the Hough method should be used. That being said,
this implementation can fine tune the provided radius, but this requires
the provided value to be reasonably close to the actual value (within
~10 pixels is ideal).</p>
<p>The ability to get subpixel precision by interpolating/fitting curves to the
convolution is currently WIP, and currently the method can, at best, give results
accurate to within a single pixel.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>singleChannelFrame</code></strong> :&ensp;<code>np.uint8[H, W]</code></dt>
<dd>The frame to perform circle detection on. Should not include multiple
color channels. If it does, the channels will be averaged to form a
grayscale image.</dd>
<dt><strong><code>radius</code></strong> :&ensp;<code>float</code> or <code>[float, float]</code></dt>
<dd>
<p>The radius to look for, or min and max radii to constrain the circle
detection. If a single value is provided, a range will be constructed
around that value with the <code>radiusTolerance</code> parameter.</p>
<p>Note that this method is more sensitive to the initial guess of radius
than <code>pepe.tracking.houghCircle()</code>. Ideally, the radius should be within
~10 pixels of the true radius (or a range of radii should only be ~15 pixels wide).</p>
<p>NOTE: Varying the radius is still under development, and likely does not work that great.</p>
</dd>
<dt><strong><code>radiusTolerance</code></strong> :&ensp;<code>float</code> or <code>None</code></dt>
<dd>
<p>The half-width of the range of radii that will be tested for detecting particles.
ie. the range will be calculated as <code>[radius + radiusTolerance, radius - radiusTolerance]</code>.</p>
<p>If set to <code>None</code>, radius will be fixed at whatever value is provided via <code>radius</code> argument.</p>
<p>NOTE: Varying the radius is still under development, and likely does not work that great.</p>
</dd>
<dt><strong><code>offscreenParticles</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether or not the algorithm should look for particles whose centers are outside of
the image domain (but some parts of the particles still show up in the image).</p>
<p>This expands the padding provided to the fft/ifft calculations, so as to avoid cutting
off what might be a potential particle. As a result, a value of True will increase computation times.</p>
</dd>
<dt><strong><code>outlineOnly</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether to look for only a particle outline (True), or to look for a filled-in circle (False).</p>
<p>See <code>outlineThickness</code>.</p>
</dd>
<dt><strong><code>outlineThickness</code></strong> :&ensp;<code>float</code> or <code>int</code></dt>
<dd>
<p>Thickness of the particle outline in the kernel; only relevant if <code>outlineOnly=True</code>.</p>
<p>If float, will be taken as fraction of the radius; if integer, will be taken as number
of pixels.</p>
</dd>
<dt><strong><code>negativeHalo</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to surround the particle mask with a region of negative value, which
further promotes identifying distinct objects as grains.</dd>
<dt><strong><code>haloThickness</code></strong> :&ensp;<code>float</code> or <code>int</code></dt>
<dd>
<p>Thickness of the negative halo in the kernel; only relevant if <code>negativeHalo=True</code>.</p>
<p>If float, will be taken as fraction of the radius; if integer, will be taken as number
of pixels.</p>
</dd>
<dt><strong><code>negativeInside</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether to fill the inside of the particle mask with a negative value, which
further promotes identifying outlines of circles.</p>
<p>Has no effect unless <code>outlineOnly=True</code>.</p>
</dd>
<dt><strong><code>peakDownsample</code></strong> :&ensp;<code>int</code></dt>
<dd>
<p>The factor by which to downsample the image when performing the initial peak
detection. The final peak detection will always be performed at the original
resolution, so this should not affect the accuracy of the detected circles,
though it is possible that some particles in a densely packed system may
not be detected. False</p>
<p>Set to <code>1</code> or <code>None</code> to perform no downsampling, though this is not recommended,
as the peak finding algorithm is O(N) where N is the total number of grid points.</p>
</dd>
<dt><strong><code>minPeakPrevalence</code></strong> :&ensp;<code>float</code></dt>
<dd>
<p>The minimum prevalence (or persistence) of peaks that will be considered as
particles. Should be a float in the range <code>[0, 1.]</code>, representing the percent
of the total intensity data range that must be spanned by a feature.</p>
<p>See <code>pepe.topology.findPeaks2D()</code> for more information.</p>
</dd>
<dt><strong><code>fitPeaks</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to fit each peak in the convolution with a lorentzian
form and use that center as the location of the particle (instead of
the simple maximum point).</dd>
<dt><strong><code>intensitySoftmax</code></strong> :&ensp;<code>float</code></dt>
<dd>
<p>Value at which to cap the intensity values in the image, calculated as
this value multipled by the mean of the image.</p>
<p>Set to <code>None</code> to skip this preprocessing step.</p>
</dd>
<dt><strong><code>intensitySoftmin</code></strong> :&ensp;<code>float</code></dt>
<dd>
<p>Zero-out all values that have an intensity below this factor times the mean of
the image.</p>
<p>Set to <code>None</code> to skip this preprocessing step.</p>
</dd>
<dt><strong><code>allowOverlap</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to allow detections of particles that overlap. If set to
False, then the particle with the stronger signature will be kept</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to draw debug information on a plot.</dd>
<dt><strong><code>invert</code></strong> :&ensp;<code>bool</code></dt>
<dd>If particles appear dark on a bright background, this will invert the
image (and convolution peak finding will go from looking for maxima
to looking for minima).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>centers</code></strong> :&ensp;<code>np.ndarray[N,2]</code></dt>
<dd>The detected circles' centers.</dd>
<dt><strong><code>radii</code></strong> :&ensp;<code>np.ndarray[N]</code></dt>
<dd>The detected circles' radii.</dd>
</dl>
<h2 id="references">References</h2>
<p>[1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
of Granular Materials. Chapter 2: Experimental Techniques. p.63-68.
CRC Press. <a href="https://doi.org/10.1201/b19291">https://doi.org/10.1201/b19291</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convCircle(singleChannelFrame, radius, radiusTolerance=None, offscreenParticles=False, kernelBlurKernel=3, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, peakDownsample=10, minPeakPrevalence=.1, intensitySoftmax=1.2, intensitySoftmin=.1, invert=False, allowOverlap=True, fitPeaks=True, debug=False):
    &#34;&#34;&#34;
    Perform convolution circle detection on the provided image.

    A brief description of the technique is described below; for
    a more comprehensive discussion, see [1].

    The convolution method identifies circles in an image by convolving
    a kernel (representing what a particle should look like) with the
    image within which you would like to detect circles. This essentially
    finds the likelihood of any particle location being the center for
    such an object. By performing peak detection on this 2D quantity,
    we can identify the most likely places for particles to be.

    While this technique can be used for non-circular objects, this 
    implementation makes use of several simplifications/approximations
    that make it suitable only for radially symmetric objects.

    Tends to give more accurate and consistent results than the Hough
    technique (see `pepe.tracking.houghCircle()`), though evaluation
    times can be longer. When the radius of the circle is not well known
    (with no initial guess), the Hough method should be used. That being said,
    this implementation can fine tune the provided radius, but this requires
    the provided value to be reasonably close to the actual value (within 
    ~10 pixels is ideal).

    The ability to get subpixel precision by interpolating/fitting curves to the
    convolution is currently WIP, and currently the method can, at best, give results
    accurate to within a single pixel.

    
    Parameters
    ----------
 
    singleChannelFrame : np.uint8[H, W]
        The frame to perform circle detection on. Should not include multiple
        color channels. If it does, the channels will be averaged to form a
        grayscale image.

    radius : float or [float, float]
        The radius to look for, or min and max radii to constrain the circle
        detection. If a single value is provided, a range will be constructed
        around that value with the `radiusTolerance` parameter.

        Note that this method is more sensitive to the initial guess of radius
        than `pepe.tracking.houghCircle()`. Ideally, the radius should be within
        ~10 pixels of the true radius (or a range of radii should only be ~15 pixels wide).

        NOTE: Varying the radius is still under development, and likely does not work that great.

    radiusTolerance : float or None
        The half-width of the range of radii that will be tested for detecting particles.
        ie. the range will be calculated as `[radius + radiusTolerance, radius - radiusTolerance]`.

        If set to `None`, radius will be fixed at whatever value is provided via `radius` argument.

        NOTE: Varying the radius is still under development, and likely does not work that great.

    offscreenParticles : bool
        Whether or not the algorithm should look for particles whose centers are outside of
        the image domain (but some parts of the particles still show up in the image).

        This expands the padding provided to the fft/ifft calculations, so as to avoid cutting
        off what might be a potential particle. As a result, a value of True will increase computation times.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    peakDownsample : int
        The factor by which to downsample the image when performing the initial peak
        detection. The final peak detection will always be performed at the original
        resolution, so this should not affect the accuracy of the detected circles,
        though it is possible that some particles in a densely packed system may
        not be detected. False

        Set to `1` or `None` to perform no downsampling, though this is not recommended,
        as the peak finding algorithm is O(N) where N is the total number of grid points.

    minPeakPrevalence : float
        The minimum prevalence (or persistence) of peaks that will be considered as
        particles. Should be a float in the range `[0, 1.]`, representing the percent
        of the total intensity data range that must be spanned by a feature.

        See `pepe.topology.findPeaks2D()` for more information.

    fitPeaks : bool
        Whether or not to fit each peak in the convolution with a lorentzian
        form and use that center as the location of the particle (instead of
        the simple maximum point).

    intensitySoftmax : float
        Value at which to cap the intensity values in the image, calculated as
        this value multipled by the mean of the image.

        Set to `None` to skip this preprocessing step.

    intensitySoftmin : float
        Zero-out all values that have an intensity below this factor times the mean of
        the image.

        Set to `None` to skip this preprocessing step.

    allowOverlap : bool
        Whether or not to allow detections of particles that overlap. If set to
        False, then the particle with the stronger signature will be kept
        
    debug : bool
        Whether or not to draw debug information on a plot. 

    invert : bool
        If particles appear dark on a bright background, this will invert the
        image (and convolution peak finding will go from looking for maxima
        to looking for minima).
   
    Returns
    -------

    centers : np.ndarray[N,2]
        The detected circles&#39; centers.

    radii : np.ndarray[N]
        The detected circles&#39; radii.


    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.63-68.
    CRC Press. https://doi.org/10.1201/b19291

    &#34;&#34;&#34;
    # General housekeeping of arguments, see if we need to parse anything
    if offscreenParticles:
        paddingFactor = 2.
    else:
        paddingFactor = 1.1

    if peakDownsample is None:
        peakDownsample = 1
 
    # Check if we are given a range of radii or just a single value
    possibleRadii = None

    if hasattr(radius, &#39;__iter__&#39;):
        if len(radius) == 2 and radius[0] &lt; radius[1]:
           possibleRadii = np.arange(radius[0], radius[1]+1)
        else:
            raise Exception(f&#39;Invalid radius provided to convCircle()!\n Expected scalar or [min, max], but got {radius}!&#39;)
    elif radiusTolerance is not None:
        # Use the tolerance
        possibleRadii = np.arange(radius - radiusTolerance, radius + radiusTolerance)
    else:
        # Just the single value
        possibleRadii = np.array([radius])

    # Start with just the mean of the possible radii options
    initialRadius = np.mean(possibleRadii)

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = np.copy(singleChannelFrame)
            
    if invert:
        imageArr = np.max(imageArr) - imageArr

    if intensitySoftmax is not None:
        softmax = np.mean(imageArr) * intensitySoftmax
        if not invert:
            imageArr[imageArr &gt;= softmax] = softmax
        #else:
        #    imageArr[255 - imageArr &gt;= softmax] = softmax

    if intensitySoftmin is not None:
        softmin = np.mean(imageArr) * intensitySoftmin
        if not invert:
            imageArr[imageArr &lt;= softmin] = 0
        #else:
        #    imageArr[255 - imageArr &lt;= softmin] = 0

    # Calculate convolution
    convArr = circularKernelFind(imageArr, initialRadius, fftPadding=int(initialRadius*paddingFactor),
                                 outlineOnly=outlineOnly, outlineThickness=outlineThickness,
                                 negativeHalo=negativeHalo, haloThickness=haloThickness,
                                 negativeInside=negativeInside, kernelBlurKernel=kernelBlurKernel, debug=debug)

    if debug:
        plt.show()

    # Downsample data by 5-10x and run peak detection
    downsampledConvArr = cv2.resize(cv2.blur(convArr, (peakDownsample,peakDownsample)), (0,0),
                                    fx=1/peakDownsample, fy=1/peakDownsample, interpolation=cv2.INTER_CUBIC)

    peakPositions, peakPrevalences = findPeaks2D(downsampledConvArr, minPeakPrevalence=minPeakPrevalence)

    lorentzPositions = np.zeros((len(peakPositions), 2))
    cleanedConvArr = np.zeros_like(convArr)

    # We have the option to fit lorentzian peaks to each maximum in the convolution
    # matrix, or we can just take the peak positions as they are
    if fitPeaks:
        def objectiveFunction(params, localImage):
            # Create a small grid across the area
            Y,X = np.ogrid[:localImage.shape[0], :localImage.shape[1]]
            Y += int(params[&#34;center_y&#34;] - localImage.shape[0]/2)
            X += int(params[&#34;center_x&#34;] - localImage.shape[1]/2)

            lorentzArr = lorentzian([Y,X], [params[&#34;center_y&#34;], params[&#34;center_x&#34;]], params[&#34;width&#34;], params[&#34;amp&#34;], params[&#34;offset&#34;])
            
            return np.sum((localImage - lorentzArr)**2)

        # Now we fit an appropriate function to each peak to see if we can refine the center
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            imagePadding = int(np.mean(possibleRadii))
            # Crop out the small area of the image around the peak
            localConv = convArr[max(upsampledPosition[0]-imagePadding, 0):min(upsampledPosition[0]+imagePadding,convArr.shape[0]-1), max(upsampledPosition[1]-imagePadding, 0):min(upsampledPosition[1]+imagePadding, convArr.shape[1]-1)]


            #plt.imshow(localConv)
            #plt.show()
            # Now setup a fit to this function
            params = Parameters()

            params.add(&#39;center_y&#39;, value=localConv.shape[0]/2, vary=True)
            params.add(&#39;center_x&#39;, value=localConv.shape[1]/2, vary=True)
            params.add(&#39;width&#39;, value=imagePadding/2, vary=False)
            params.add(&#39;amp&#39;, value=np.max(localConv)-np.min(localConv), vary=False)
            params.add(&#39;offset&#39;, value=np.min(localConv), vary=False)
        
            result = minimize(objectiveFunction, params, args=[localConv], method=&#39;nelder&#39;, max_nfev=10000)
            
            if result is not None:
                lorentzPositions[i,0] = upsampledPosition[0] - localConv.shape[0]/2 + result.params[&#34;center_y&#34;]
                lorentzPositions[i,1] = upsampledPosition[1] - localConv.shape[1]/2 + result.params[&#34;center_x&#34;]

                Y,X = np.ogrid[:convArr.shape[0], :convArr.shape[1]]
                cleanedConvArr += lorentzian([Y,X], lorentzPositions[i], result.params[&#34;width&#34;], result.params[&#34;amp&#34;], result.params[&#34;offset&#34;])

            else:
                lorentzPositions[i] = upsampledPosition

    else:
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            lorentzPositions[i] = upsampledPosition

    # Look around each peak to find the real peak in the full-resolution image
    # (only if we are actually downsampling)
    refinedPeakPositions = []
    refinedRadii = []

    if peakDownsample &gt; 1:
        # To do this, we use a non-linear optimization scheme
        for i in range(len(peakPositions)):

            costArr = []

            def refineObjectiveFunction(params):
                kernelArr = genCircularKernel(np.array([params[&#34;y&#34;].value, params[&#34;x&#34;].value]), params[&#34;r&#34;].value,
                                              imageArr.shape, kernelBlurKernel, outlineOnly,
                                              outlineThickness, negativeHalo, haloThickness, negativeInside)

                # We are minimizing this function, so we need the cost to be negative
                # (unless we have to invert the image)
                costArr.append((np.sum(kernelArr * imageArr) / np.sum(kernelArr)) * (int(invert)*2 - 1))
                return (np.sum(kernelArr * imageArr) / np.sqrt(np.sum(kernelArr))) * (int(invert)*2 - 1)

            params = Parameters()

            params.add(&#39;y&#39;, value=lorentzPositions[i][0], min=lorentzPositions[i][0]-imageArr.shape[0]*.02, max=lorentzPositions[i][0]+imageArr.shape[0]*.02)
            params.add(&#39;x&#39;, value=lorentzPositions[i][1], min=lorentzPositions[i][1]-imageArr.shape[1]*.02, max=lorentzPositions[i][1]+imageArr.shape[1]*.02)
            # May or may not want to vary the radius
            # Small tolerances on the radius are so that min != max
            params.add(&#39;r&#39;, value=np.mean(possibleRadii), vary=(len(possibleRadii) &gt; 1), max=np.max(possibleRadii)-.01, min=np.min(possibleRadii)+.01)

            result = minimize(refineObjectiveFunction, params, method=&#39;powell&#39;, max_nfev=10000, options={&#34;ftol&#34;: 1e-5, &#34;xtol&#34;: 1e-5})

            #print(fit_report(result))

            if result is not None:
                refinedPeakPositions.append([result.params[&#34;y&#34;].value, result.params[&#34;x&#34;].value])
                refinedRadii.append(result.params[&#34;r&#34;].value)
                
                #if debug:
                #    plt.plot(costArr)
                #    plt.show()

            else:
                refinedPeakPositions.append(lorentzPositions[i])
                refinedRadii.append(np.mean(possibleRadii))

    else:
        refinedPeakPositions = lorentzPositions
        refinedRadii = np.repeat(np.mean(possibleRadii), len(refinedPeakPositions))


    # Now we (optionally) remove overlapping particles
    # TODO: Allow overlap to be a float value, which allows overlaps
    # that do not exceed a certain threshold (eg. that fraction of the radius).
    if not allowOverlap:
        # Calculate the contact matrix
        # negative contact padding because we don&#39;t want to remove particles that are
        # good but just close to each other
        adjMat = adjacencyMatrix(refinedPeakPositions, refinedRadii, contactPadding=-int(np.mean(refinedRadii)/10)) - np.eye(len(refinedPeakPositions))

        # Locate all of the particles that are overlapping
        overlappingParticles = np.array([i for i in range(len(refinedPeakPositions)) if np.sum(adjMat[i,:]) &gt; 0])

        # Now find how good of detections each of these is, and order them from worst to best.
        particleScores = np.zeros(len(overlappingParticles))
        for i in range(len(particleScores)):
            # Need to convert to int16 since we might have negative values
            pMask = genCircularKernel(refinedPeakPositions[i], refinedRadii[i],
                                      singleChannelFrame.shape, kernelBlurKernel, outlineOnly,
                                      outlineThickness, negativeHalo, haloThickness, negativeInside).astype(np.int16)

            if np.sum(pMask) &gt; 0:
                # I square-root the mask sum so that the particles at the edge don&#39;t
                # always win out against actual particles
                # TODO: This still doesn&#39;t give priority to particles on screen;
                # need to figure out a way to do that
                particleScores[i] = np.sum(singleChannelFrame * pMask) / np.sqrt(np.sum(pMask))
            else:
                particleScores[i] = 0 

        # Sort according to worst scores
        order = np.argsort(particleScores)[::-1]
        overlappingParticles = overlappingParticles[order]

        # Now we start removing the particles with the worst scores until we no longer have overlap
        index = 0
        while np.sum(adjMat) &gt; 0:
            adjMat[overlappingParticles[index],:] = 0
            adjMat[:,overlappingParticles[index]] = 0
            refinedPeakPositions[overlappingParticles[index]] = None
            refinedRadii[overlappingParticles[index]] = None

            index += 1

           
        # Now remove all of the None values we put in
        refinedPeakPositions = [rpp for rpp in refinedPeakPositions if rpp is not None]
        refinedRadii = [rr for rr in refinedRadii if rr is not None]


    # Debug option
    if debug:
        fig = plt.figure(figsize=(12,4))

        ax1 = fig.add_subplot(1, 3, 1, projection=&#39;3d&#39;)
        ax1.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), convArr, cmap=plt.cm.jet)
        ax1.set_title(&#39;Convolution&#39;)

        ax2 = fig.add_subplot(1, 3, 2, projection=&#39;3d&#39;)
        ax2.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), cleanedConvArr, cmap=plt.cm.jet)
        ax2.set_title(&#39;Cleaned Convolution&#39;)

        ax3 = fig.add_subplot(1, 3, 3)
        ax3.imshow(singleChannelFrame)
        ax3.set_title(&#39;Detected circles&#39;)
        for i in range(len(refinedPeakPositions)):
            c = plt.Circle(refinedPeakPositions[i][::-1], refinedRadii[i], color=&#39;red&#39;, fill=False, linewidth=1)
            ax3.add_artist(c)

        fig.tight_layout()

    return np.array(refinedPeakPositions), np.array(refinedRadii)</code></pre>
</details>
</dd>
<dt id="pepe.tracking.Convolution.genCircularKernel"><code class="name flex">
<span>def <span class="ident">genCircularKernel</span></span>(<span>center, radius, imageShape, kernelBlurKernel=3, outlineOnly=False, outlineThickness=0.05, negativeHalo=False, haloThickness=0.03, negativeInside=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def genCircularKernel(center, radius, imageShape, kernelBlurKernel=3, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False,):

    kernelArr = circularMask(imageShape, center, radius)[:,:,0].astype(np.float64)

    # If we only want the outline, we subtract another circular mask from the above one
    if outlineOnly:
        # Should be 2 if negative inside is true, 1 otherwise
        negativeInsideFactor = 1 + int(negativeInside)
        if outlineThickness &lt; 1:
            innerRadius = np.ceil((1 - outlineThickness) * radius)
        else:
            innerRadius = radius - outlineThickness
        
        kernelArr = kernelArr - negativeInsideFactor * circularMask(imageShape, center, innerRadius)[:,:,0].astype(np.float64)

        if negativeHalo:
            if haloThickness &lt; 1:
                haloRadius = radius + np.ceil((1 - haloThickness) * radius)
            else:
                haloRadius = radius + haloThickness

            kernelArr = 2*kernelArr - (circularMask(imageShape, center, haloRadius)[:,:,0].astype(np.float64) - circularMask(imageShape, center, radius)[:,:,0].astype(np.float64))

    elif negativeHalo:
        if haloThickness &lt; 1:
            haloRadius = np.ceil((1 + haloThickness) * radius)
        else:
            haloRadius = radius + haloThickness

        kernelArr = 2*kernelArr - circularMask(imageShape, center, haloRadius)[:,:,0].astype(np.float64)

    if kernelBlurKernel is not None and kernelBlurKernel &gt; 0:
        kernelArr = cv2.blur(kernelArr, (kernelBlurKernel,kernelBlurKernel))

    return kernelArr</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pepe.tracking" href="index.html">pepe.tracking</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pepe.tracking.Convolution.circularKernelFind" href="#pepe.tracking.Convolution.circularKernelFind">circularKernelFind</a></code></li>
<li><code><a title="pepe.tracking.Convolution.convCircle" href="#pepe.tracking.Convolution.convCircle">convCircle</a></code></li>
<li><code><a title="pepe.tracking.Convolution.genCircularKernel" href="#pepe.tracking.Convolution.genCircularKernel">genCircularKernel</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>