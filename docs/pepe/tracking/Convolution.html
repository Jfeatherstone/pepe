<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pepe.tracking.Convolution API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pepe.tracking.Convolution</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import cv2
import matplotlib.pyplot as plt

import numba
from scipy.fft import fft2, ifft2

from pepe.preprocess import circularMask, rectMask
from pepe.topology import findPeaks2D
from pepe.utils import lorentzian
from pepe.analysis import adjacencyMatrix

from lmfit import minimize, Parameters

def convCircle(singleChannelFrame, radius, radiusTolerance=None, offscreenParticles=False, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, peakDownsample=10, minPeakPrevalence=.1, intensitySoftmax=1.2, intensitySoftmin=.1, invert=False, allowOverlap=False, fitPeaks=True, debug=False):
    &#34;&#34;&#34;
    Perform convolution circle detection on the provided image.

    A brief description of the technique is described below; for
    a more comprehensive discussion, see [1].

    The convolution method identifies circles in an image by convolving
    a kernel (representing what a particle should look like) with the
    image within which you would like to detect circles. This essentially
    finds the likelihood of any particle location being the center for
    such an object. By performing peak detection on this 2D quantity,
    we can identify the most likely places for particles to be.

    While this technique can be used for non-circular objects, this 
    implementation makes use of several simplifications/approximations
    that make it suitable only for radially symmetric objects.

    Tends to give more accurate and consistent results than the Hough
    technique (see `pepe.tracking.houghCircle()`), though evaluation
    times can be longer. When the radius of the circle is not well known
    (with no initial guess), the Hough method should be used. That being said,
    this implementation can fine tune the provided radius, but this requires
    the provided value to be reasonably close to the actual value (within 
    ~10 pixels is ideal).

    The ability to get subpixel precision by interpolating/fitting curves to the
    convolution is currently WIP, and currently the method can, at best, give results
    accurate to within a single pixel.

    
    Parameters
    ----------
 
    singleChannelFrame : np.uint8[H, W]
        The frame to perform circle detection on. Should not include multiple
        color channels. If it does, the channels will be averaged to form a
        grayscale image.

    radius : float or [float, float]
        The radius to look for, or min and max radii to constrain the circle
        detection. If a single value is provided, a range will be constructed
        around that value with the `radiusTolerance` parameter.

        Note that this method is more sensitive to the initial guess of radius
        than `pepe.tracking.houghCircle()`. Ideally, the radius should be within
        ~10 pixels of the true radius (or a range of radii should only be ~15 pixels wide).

        NOTE: Varying the radius is still under development, and likely does not work that great.

    radiusTolerance : float or None
        The half-width of the range of radii that will be tested for detecting particles.
        ie. the range will be calculated as `[radius + radiusTolerance, radius - radiusTolerance]`.

        If set to `None`, radius will be fixed at whatever value is provided via `radius` argument.

        NOTE: Varying the radius is still under development, and likely does not work that great.

    offscreenParticles : bool
        Whether or not the algorithm should look for particles whose centers are outside of
        the image domain (but some parts of the particles still show up in the image).

        This expands the padding provided to the fft/ifft calculations, so as to avoid cutting
        off what might be a potential particle. As a result, a value of True will increase computation times.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    peakDownsample : int
        The factor by which to downsample the image when performing the initial peak
        detection. The final peak detection will always be performed at the original
        resolution, so this should not affect the accuracy of the detected circles,
        though it is possible that some particles in a densely packed system may
        not be detected. False

        Set to `1` or `None` to perform no downsampling, though this is not recommended,
        as the peak finding algorithm is O(N) where N is the total number of grid points.

    minPeakPrevalence : float
        The minimum prevalence (or persistence) of peaks that will be considered as
        particles. Should be a float in the range `[0, 1.]`, representing the percent
        of the total intensity data range that must be spanned by a feature.

        See `pepe.topology.findPeaks2D()` for more information.

    fitPeaks : bool
        Whether or not to fit each peak in the convolution with a lorentzian
        form and use that center as the location of the particle (instead of
        the simple maximum point).

    intensitySoftmax : float
        Value at which to cap the intensity values in the image, calculated as
        this value multipled by the mean of the image.

        Set to `None` to skip this preprocessing step.

    intensitySoftmin : float
        Zero-out all values that have an intensity below this factor times the mean of
        the image.

        Set to `None` to skip this preprocessing step.
        
    debug : bool
        Whether or not to draw debug information on a plot. 

    invert : bool
        If particles appear dark on a bright background, this will invert the
        image (and convolution peak finding will go from looking for maxima
        to looking for minima).
   
    Returns
    -------

    centers : np.ndarray[N,2]
        The detected circles&#39; centers.

    radii : np.ndarray[N]
        The detected circles&#39; radii.


    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.63-68.
    CRC Press. https://doi.org/10.1201/b19291

    &#34;&#34;&#34;

    # General housekeeping of arguments, see if we need to parse anything
    if offscreenParticles:
        paddingFactor = 2.
    else:
        paddingFactor = 1.1

    if peakDownsample is None:
        peakDownsample = 1
 
    # Check if we are given a range of radii or just a single value
    possibleRadii = None

    if hasattr(radius, &#39;__iter__&#39;):
        if len(radius) == 2 and radius[0] &lt; radius[1]:
           possibleRadii = np.arange(radius[0], radius[1]+1)
        else:
            raise Exception(f&#39;Invalid radius provided to convCircle()!\n Expected scalar or [min, max], but got {radius}!&#39;)
    elif radiusTolerance is not None:
        # Use the tolerance
        possibleRadii = np.arange(radius - radiusTolerance, radius + radiusTolerance)
    else:
        # Just the single value
        possibleRadii = np.array([radius])

    # Start with just the mean of the possible radii options
    initialRadius = np.mean(possibleRadii)

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = np.copy(singleChannelFrame)
            
    if invert:
        imageArr = np.max(imageArr) - imageArr

    if intensitySoftmax is not None:
        softmax = np.mean(imageArr) * intensitySoftmax
        if not invert:
            imageArr[imageArr &gt;= softmax] = softmax
        #else:
        #    imageArr[255 - imageArr &gt;= softmax] = softmax

    if intensitySoftmin is not None:
        softmin = np.mean(imageArr) * intensitySoftmin
        if not invert:
            imageArr[imageArr &lt;= softmin] = 0
        #else:
        #    imageArr[255 - imageArr &lt;= softmin] = 0

    # Calculate convolution
    convArr = circularKernelFind(imageArr, initialRadius, fftPadding=int(initialRadius*paddingFactor),
                                 outlineOnly=outlineOnly, outlineThickness=outlineThickness,
                                 negativeHalo=negativeHalo, haloThickness=haloThickness,
                                 negativeInside=negativeInside, debug=debug)

    if debug:
        plt.show()

    # Downsample data by 5-10x and run peak detection
    downsampledConvArr = cv2.resize(cv2.blur(convArr, (peakDownsample,peakDownsample)), (0,0),
                                    fx=1/peakDownsample, fy=1/peakDownsample, interpolation=cv2.INTER_CUBIC)

    peakPositions, peakPrevalences = findPeaks2D(downsampledConvArr, minPeakPrevalence=minPeakPrevalence)

    lorentzPositions = np.zeros((len(peakPositions), 2))
    cleanedConvArr = np.zeros_like(convArr)

    # We have the option to fit lorentzian peaks to each maximum in the convolution
    # matrix, or we can just take the peak positions as they are
    if fitPeaks:
        def objectiveFunction(params, localImage):
            # Create a small grid across the area
            Y,X = np.ogrid[:localImage.shape[0], :localImage.shape[1]]
            Y += int(params[&#34;center_y&#34;] - localImage.shape[0]/2)
            X += int(params[&#34;center_x&#34;] - localImage.shape[1]/2)

            lorentzArr = lorentzian([Y,X], [params[&#34;center_y&#34;], params[&#34;center_x&#34;]], params[&#34;width&#34;], params[&#34;amp&#34;], params[&#34;offset&#34;])
            
            return np.sum((localImage - lorentzArr)**2)

        # Now we fit an appropriate function to each peak to see if we can refine the center
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            imagePadding = int(np.mean(possibleRadii))
            # Crop out the small area of the image around the peak
            localConv = convArr[max(upsampledPosition[0]-imagePadding, 0):min(upsampledPosition[0]+imagePadding,convArr.shape[0]-1), max(upsampledPosition[1]-imagePadding, 0):min(upsampledPosition[1]+imagePadding, convArr.shape[1]-1)]


            #plt.imshow(localConv)
            #plt.show()
            # Now setup a fit to this function
            params = Parameters()

            params.add(&#39;center_y&#39;, value=localConv.shape[0]/2, vary=True)
            params.add(&#39;center_x&#39;, value=localConv.shape[1]/2, vary=True)
            params.add(&#39;width&#39;, value=imagePadding/2, vary=False)
            params.add(&#39;amp&#39;, value=np.max(localConv)-np.min(localConv), vary=False)
            params.add(&#39;offset&#39;, value=np.min(localConv), vary=False)
        
            result = minimize(objectiveFunction, params, args=[localConv], method=&#39;nelder&#39;, max_nfev=10000)
            
            if result is not None:
                lorentzPositions[i,0] = upsampledPosition[0] - localConv.shape[0]/2 + result.params[&#34;center_y&#34;]
                lorentzPositions[i,1] = upsampledPosition[1] - localConv.shape[1]/2 + result.params[&#34;center_x&#34;]

                Y,X = np.ogrid[:convArr.shape[0], :convArr.shape[1]]
                cleanedConvArr += lorentzian([Y,X], lorentzPositions[i], result.params[&#34;width&#34;], result.params[&#34;amp&#34;], result.params[&#34;offset&#34;])

            else:
                lorentzPositions[i] = upsampledPosition

    else:
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            lorentzPositions[i] = upsampledPosition

    # Look around each peak to find the real peak in the full-resolution image
    refinedPeakPositions = []
    refinedRadii = []

    localPadding = int(peakDownsample*1.5)
    for i in range(len(peakPositions)):
        # We want to vary the radius here as well, so we can maybe get a slightly more accurate result.
        # Note that it is much more efficient to perform the kernel finding on a small image many times
        # than to work on a large image just a few times. So we recalculate the kernel finding for each
        # radii for each peak.
        # TODO: This part is still WIP, because it doens&#39;t quite work correctly
        if len(possibleRadii) &gt; 1:
            maximumValues = np.zeros(len(possibleRadii))
            maximumPositions = np.zeros((len(possibleRadii), 2))

            #upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            upsampledPosition = np.int16(lorentzPositions[i])
            for j in range(len(possibleRadii)):
                # This is the point in the real image (not the conv arr)
                imagePadding = int(possibleRadii[j])
                # Crop out the small area of the image that we are working with
                localImage = imageArr[max(upsampledPosition[0]-imagePadding, 0):min(upsampledPosition[0]+imagePadding,imageArr.shape[0]-1),max(upsampledPosition[1]-imagePadding, 0):min(upsampledPosition[1]+imagePadding, imageArr.shape[1]-1)]

                # Perform another convolution
                # Don&#39;t need as much padding for this one, since we are quite sure the particle is somewhere
                # near the center
                localConvPadding = int(possibleRadii[j])
                localConvArr = circularKernelFind(localImage, possibleRadii[j], fftPadding=localConvPadding,
                                                  outlineOnly=outlineOnly, outlineThickness=outlineThickness,
                                                  negativeHalo=negativeHalo, haloThickness=haloThickness,
                                                  negativeInside=negativeInside, debug=False)
                # Required if you set debug=True in above line
                #plt.show()

                # Add a *very* small weighting that favors circles closer to the center of the
                # image. This is needed because otherwise the algorithm may place circles more
                # offscreen than they actually are, because it would mean fewer pixels are included
                # (since some are cropped off)
                #Y = np.arange(localImage.shape[0]).reshape((localImage.shape[0], 1)) # Column vector
                #X = np.arange(localImage.shape[1]).reshape((1, localImage.shape[1])) # Row vector
                #localConvArr += 1e-3*np.exp(- ( (Y - localImage.shape[0]/2)**2 + (X - localImage.shape[1]/2)**2 ) / max(localImage.shape))

                # Now setup a fit to this function
                params = Parameters()

                params.add(&#39;center_y&#39;, value=localImage.shape[0]/2, vary=True)
                params.add(&#39;center_x&#39;, value=localImage.shape[1]/2, vary=True)
                params.add(&#39;width&#39;, value=imagePadding, vary=True)
                params.add(&#39;amp&#39;, value=np.max(localConvArr)/2, vary=True)
                params.add(&#39;offset&#39;, value=np.mean(localConvArr), vary=True)
                
                try:
                    result = minimize(objectiveFunction, params, args=[localConvArr], method=&#39;nelder&#39;, max_nfev=1000)
                except:
                    result = None
                
                if result is not None:
                    realLocalMax = np.array([int(result.params[&#34;center_y&#34;]), int(result.params[&#34;center_x&#34;])])
                else:
                    realLocalMax = np.zeros(2)

                #realLocalMax = np.unravel_index(np.argmax(localConvArr.flatten()), localConvArr.shape)
                # We want to convert these back to real-space coordinates here
                #maximumPositions[j] = upsampledPosition - realLocalMax - np.repeat(localConvPadding, 2)
                maximumPositions[j,0] = upsampledPosition[0] - localConvArr.shape[0]/2 + realLocalMax[0]
                maximumPositions[j,1] = upsampledPosition[1] - localConvArr.shape[1]/2 + realLocalMax[1]

                # Need to convert to int16 since we might have negative values
                pMask = circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j])[:,:,0].astype(np.int16)

                # The next couple if statements are for only doing an outline, adding a halo, removing the center, etc.
                # If we only want the outline, we subtract another circular mask from the above one
                if outlineOnly:
                    # Should be 2 if negative inside is true, 1 otherwise
                    negativeInsideFactor = 1 + int(negativeInside)
                    if outlineThickness &lt; 1:
                        innerRadius = np.ceil((1 - outlineThickness) * possibleRadii[j])
                    else:
                        innerRadius = possibleRadii[j] - outlineThickness
                        pMask -= negativeInsideFactor * circularMask(singleChannelFrame.shape, maximumPositions[j], innerRadius)[:,:,0]

                    if negativeHalo:
                        pMask = 2*pMask - (circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j]+2)[:,:,0].astype(np.int16) - circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j])[:,:,0].astype(np.int16))

                elif negativeHalo:
                    pMask = 2*pMask - circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j]+2)[:,:,0].astype(np.int16)


                if np.sum(pMask) == 0:
                    maximumValues[j] = 0
                else:
                    maximumValues[j] = np.sum(singleChannelFrame * pMask) / np.sum(pMask)
           
            

            # Noise can cause some slight variations in the maximum values making different
            # radii give different maximum values, when they should give actually the same
            # value (and then the largest one should be taken). We fix this by rounding
            # after multiply by a large number. .5e3 was chosen by experimenting

            maximumValues = [int(m*1e2) if not np.isnan(m) else 0 for m in maximumValues]

            #plt.plot(possibleRadii, maximumValues)
            #plt.show()

            # Now save whichever on had the largest signal
            # We want to sort the list backwards, because we want the largest possible radius
            # that also gives the best value. If the radius is smaller than the actual one, you
            # can end up with the same exact maximum value, since you are just cutting off extra
            # parts of the circle.
            refinedPeakPositions.append(tuple(maximumPositions[::-1][np.argmax(maximumValues[::-1])]))
            refinedRadii.append(possibleRadii[::-1][np.argmax(maximumValues[::-1])])

        else:
            # Position of the peaks in the convolution image (NOT the real image)
            upsampledPosition = np.int16(lorentzPositions[i])
            
            # We don&#39;t need to refine if we fit a peak, since that already did refine the
            # position
            if fitPeaks:
                refinementOffset = 0

            else:
                # This just looks long because my naming is a little verbose
                # + we also have to make sure we don&#39;t accidentally go off of the image
                localRegion = convArr[max(upsampledPosition[0]-localPadding, 0):min(upsampledPosition[0]+localPadding,convArr.shape[0]-1),max(upsampledPosition[1]-localPadding, 0):min(upsampledPosition[1]+localPadding, convArr.shape[1]-1)]
                # Find maximum intensity in small region around that position
                realLocalMax = np.unravel_index(np.argmax(localRegion.flatten()), localRegion.shape)
                # This is relative to the small region we just created, so we have to subtract off the bounds
                # eg. if this local max was found to be in the center of the local image, that would mean
                # that the original upsampled position was correct.
                refinementOffset = realLocalMax - np.repeat(localPadding, 2)

            # Now put everything together the coordinates of the circle in the original image
            refinedPeakPositions.append(tuple(upsampledPosition + refinementOffset))
            refinedRadii.append(initialRadius)


    # Now we (optionally) remove overlapping particles
    if not allowOverlap:
        # Calculate the contact matrix
        # negative contact padding because we don&#39;t want to remove particles that are
        # good but just close to each other
        adjMat = adjacencyMatrix(refinedPeakPositions, refinedRadii, contactPadding=-int(np.mean(refinedRadii)/10)) - np.eye(len(refinedPeakPositions))

        # Locate all of the particles that are overlapping
        overlappingParticles = np.array([i for i in range(len(refinedPeakPositions)) if np.sum(adjMat[i,:]) &gt; 0])

        # Now find how good of detections each of these is, and order them from worst to best.
        particleScores = np.zeros(len(overlappingParticles))
        for i in range(len(particleScores)):
            # Need to convert to int16 since we might have negative values
            pMask = circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i])[:,:,0].astype(np.int16)

            # The next couple if statements are for only doing an outline, adding a halo, removing the center, etc.
            # If we only want the outline, we subtract another circular mask from the above one
            if outlineOnly:
                # Should be 2 if negative inside is true, 1 otherwise
                negativeInsideFactor = 1 + int(negativeInside)
                if outlineThickness &lt; 1:
                    innerRadius = np.ceil((1 - outlineThickness) * refinedRadii[i])
                else:
                    innerRadius = refinedRadii[i] - outlineThickness
                    pMask -= negativeInsideFactor * circularMask(singleChannelFrame.shape, refinedPeakPositions[i], innerRadius)[:,:,0]

                if negativeHalo:
                    pMask = 2*pMask - (circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i]+2)[:,:,0].astype(np.int16) - circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i])[:,:,0].astype(np.int16))

            elif negativeHalo:
                pMask = 2*pMask - circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i]+2)[:,:,0].astype(np.int16)

            if np.sum(pMask) &gt; 0:
                # I square-root the mask sum so that the particles at the edge don&#39;t
                # always win out against actual particles
                # TODO: This still doesn&#39;t give priority to particles on screen;
                # need to figure out a way to do that
                particleScores[i] = np.sum(singleChannelFrame * pMask) / np.sqrt(np.sum(pMask))
            else:
                particleScores[i] = 0 

        # Sort according to worst scores
        order = np.argsort(particleScores)[::-1]
        overlappingParticles = overlappingParticles[order]

        # Now we start removing the particles with the worst scores until we no longer have overlap
        index = 0
        while np.sum(adjMat) &gt; 0:
            adjMat[overlappingParticles[index],:] = 0
            adjMat[:,overlappingParticles[index]] = 0
            refinedPeakPositions[overlappingParticles[index]] = None
            refinedRadii[overlappingParticles[index]] = None

            index += 1

           
        # Now remove all of the None values we put in
        refinedPeakPositions = [rpp for rpp in refinedPeakPositions if rpp is not None]
        refinedRadii = [rr for rr in refinedRadii if rr is not None]


    # Debug option
    if debug:
        fig = plt.figure(figsize=(12,4))

        ax1 = fig.add_subplot(1, 3, 1, projection=&#39;3d&#39;)
        ax1.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), convArr, cmap=plt.cm.jet)
        ax1.set_title(&#39;Convolution&#39;)

        ax2 = fig.add_subplot(1, 3, 2, projection=&#39;3d&#39;)
        ax2.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), cleanedConvArr, cmap=plt.cm.jet)
        ax2.set_title(&#39;Cleaned Convolution&#39;)

        ax3 = fig.add_subplot(1, 3, 3)
        ax3.imshow(singleChannelFrame)
        ax3.set_title(&#39;Detected circles&#39;)
        for i in range(len(refinedPeakPositions)):
            c = plt.Circle(refinedPeakPositions[i][::-1], refinedRadii[i], color=&#39;red&#39;, fill=False, linewidth=1)
            ax3.add_artist(c)

        fig.tight_layout()

    return np.array(refinedPeakPositions), np.array(refinedRadii)


def circularKernelFind(singleChannelFrame, radius, fftPadding, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, paddingValue=None, debug=False):
    &#34;&#34;&#34;
    Calculate the convolution of a circular mask with an image,
    identifying likely locations of circles within the image. Adapted from
    method described in [1].

    To perform the convolution, we take the product of the fft of each the
    kernel and image, and then ifft the result to transform back to real space.
    The only peculiarity is that there can be some issues with the edges of image
    (especially if any circle centers are near the edge/off-screen) so we
    have to take care to properly pad the image and the kernel.

    Note that this method is not intended to be used as the front end for
    circle detection for real data. The method `pepe.tracking.convCircle()`
    makes use of this method to track circles, while also offering many more
    features. It is recommended to use that function unless there is a very
    specific purpose that it does not serve.

    Parameters
    ----------
    singleChannelFrame : np.ndarray[H,W]
        A single-channel image (grayscale or just one channel) within which we
        are looking to identify circular objects.

    radius : float
        The radius of circles to detect in the image.

    fftPadding : int
        The amount of padding to add to each side of the image, to prevent the
        fft from having issues. A good choice is usually 1.5 times the radius,
        though, less padding can be used if circles are not expected to often
        be located near the edges.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    paddingValue : [float, `&#39;sigmoid&#39;`, or `None`]
        What value to fill in for the extra padding that is added during the fft/ifft.

        `None` leaves the value at 0.

        `&#39;sigmoid&#39;` will create a smooth-ish transition to 0.

        Any float value will be inserted into every point.

    debug : bool
        Whether or not to plot various quantities of the calculation for inspection
- `S`: Soft particles; shore hardness 40
- `M`: Medium particles; shore hardness 50
- `H`: Hard particles; shore hardness 60, thickness
        at the end of the evaluation.

    Returns
    -------

    chiSqr : np.ndarray[H,W]
        The convolution of the kernel with the image. Larger values represent
        higher likelihood that there is a particle centered there.

    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.64-68.
    CRC Press. https://doi.org/10.1201/b19291
    &#34;&#34;&#34;

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = singleChannelFrame

    fftPadding = int(fftPadding)

    # Pad the proper image
    paddedImageArr = np.zeros((int(imageArr.shape[0] + 2*fftPadding), int(imageArr.shape[1] + 2*fftPadding)))
    paddedImageArr[fftPadding:-fftPadding,fftPadding:-fftPadding] = imageArr

    # Both dimensions will always have the same first crop index, but possibly a different second one
    cropBounds = [int(fftPadding + radius), int(-fftPadding + radius), int(-fftPadding + radius)]
    # If the fftpadding and the radius are exactly the same, we get some weird behavior
    # This happens because python can index negative values as that element from the end of
    # the array, but indexing -0 just gives 0, and so it gives you a (0,0) array.
    if cropBounds[1] &gt;= 0:
        cropBounds[1] = None
        cropBounds[2] = None

    # We have a couple options for what values to put in the padding
    if paddingValue is None or paddingValue == 0:
        # Do nothing, and leave the value at 0
        pass

    elif paddingValue == &#39;sigmoid&#39;:
        # Sigmoid gives a smoothish decay from the image to 0 at the boundaries
        # Most of the constants here are just arbitrarily chosen to make things look good
        # Top
        paddedImageArr[:fftPadding] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[fftPadding])[::-1,:] 
        # Bottom
        paddedImageArr[-fftPadding:] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[-fftPadding-1])
        # Left
        paddedImageArr[:,:fftPadding] += np.multiply.outer(paddedImageArr[:,fftPadding], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))[:,::-1]
        # Right
        paddedImageArr[:,-fftPadding:] += np.multiply.outer(paddedImageArr[:,-fftPadding-1], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))

    else:
        # Just put a fixed value in
        paddedImageArr[:fftPadding] = paddingValue
        paddedImageArr[-fftPadding:] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,:fftPadding] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,-fftPadding:] = paddingValue

    center = np.array([radius,radius])
    # To be able to properly convolute the kernel with the image, they have to
    # be the same size, so just just put our kernel into an array the same size
    # as the image (though most entries will just be zero)
    kernelArr = circularMask(paddedImageArr.shape, center, radius)[:,:,0].astype(np.float64)
   
    # If we only want the outline, we subtract another circular mask from the above one
    if outlineOnly:
        # Should be 2 if negative inside is true, 1 otherwise
        negativeInsideFactor = 1 + int(negativeInside)
        if outlineThickness &lt; 1:
            innerRadius = np.ceil((1 - outlineThickness) * radius)
        else:
            innerRadius = radius - outlineThickness
        
        kernelArr = kernelArr - negativeInsideFactor * circularMask(paddedImageArr.shape, center, innerRadius)[:,:,0].astype(np.float64)

        if negativeHalo:
            if haloThickness &lt; 1:
                haloRadius = radius + np.ceil((1 - haloThickness) * radius)
            else:
                haloRadius = radius + haloThickness

            kernelArr = 2*kernelArr - (circularMask(paddedImageArr.shape, center, haloRadius)[:,:,0].astype(np.float64) - circularMask(paddedImageArr.shape, center, radius)[:,:,0].astype(np.float64))

    elif negativeHalo:
        if haloThickness &lt; 1:
            haloRadius = np.ceil((1 + haloThickness) * radius)
        else:
            haloRadius = radius + haloThickness

        kernelArr = 2*kernelArr - circularMask(paddedImageArr.shape, center, haloRadius)[:,:,0].astype(np.float64)

    # First convolutional term
    convTerm1 = ifft2(fft2(paddedImageArr**2) * fft2(kernelArr))
    # Trim padding
    convTerm1 = convTerm1[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # Second term is pretty easy since we choose our weight function to be our
    # particle mask (and it just has 0s and 1s, so it is equal to it&#39;s square)
    convTerm2 = 2 * ifft2(fft2(paddedImageArr) * fft2(kernelArr))
    # Trim padding
    convTerm2 = convTerm2[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # For the normalization term, we want to sum all parts of the kernel that are
    # on screen (in the original image&#39;s frame) as we translate it across the image.
    originalImageMask = rectMask(paddedImageArr.shape, np.repeat(fftPadding, 2), np.array(imageArr.shape))[:,:,0]
    normalizationTerm = ifft2(fft2(originalImageMask) * fft2(kernelArr))
    # Trim padding
    normalizationTerm = np.real(normalizationTerm[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]])
    # Put everything together
    # Technically there is a +1 here, but that won&#39;t affect any minima, so we don&#39;t really care
    chiSqr = np.real((convTerm1 - convTerm2) / normalizationTerm)
    if np.min(chiSqr) &lt; 0 and np.max(chiSqr) &lt; 0:
        chiSqr = np.abs(chiSqr)

    if debug:
        fig, ax = plt.subplots(1, 4, figsize=(13,4))

        ax[0].imshow(kernelArr)
        ax[0].set_title(&#39;Kernel&#39;)

        ax[1].imshow(paddedImageArr)
        ax[1].set_title(&#39;Padded image&#39;)

        ax[2].imshow(normalizationTerm)
        ax[2].set_title(&#39;Normalization&#39;)

        ax[3].imshow(chiSqr)
        ax[3].set_title(&#39;Real-space convolution (Re)&#39;)

        fig.tight_layout()

    return chiSqr</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pepe.tracking.Convolution.circularKernelFind"><code class="name flex">
<span>def <span class="ident">circularKernelFind</span></span>(<span>singleChannelFrame, radius, fftPadding, outlineOnly=False, outlineThickness=0.05, negativeHalo=False, haloThickness=0.03, negativeInside=False, paddingValue=None, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the convolution of a circular mask with an image,
identifying likely locations of circles within the image. Adapted from
method described in [1].</p>
<pre><code>To perform the convolution, we take the product of the fft of each the
kernel and image, and then ifft the result to transform back to real space.
The only peculiarity is that there can be some issues with the edges of image
(especially if any circle centers are near the edge/off-screen) so we
have to take care to properly pad the image and the kernel.

Note that this method is not intended to be used as the front end for
circle detection for real data. The method &lt;code&gt;pepe.tracking.convCircle()&lt;/code&gt;
makes use of this method to track circles, while also offering many more
features. It is recommended to use that function unless there is a very
specific purpose that it does not serve.

Parameters
----------
singleChannelFrame : np.ndarray[H,W]
    A single-channel image (grayscale or just one channel) within which we
    are looking to identify circular objects.

radius : float
    The radius of circles to detect in the image.

fftPadding : int
    The amount of padding to add to each side of the image, to prevent the
    fft from having issues. A good choice is usually 1.5 times the radius,
    though, less padding can be used if circles are not expected to often
    be located near the edges.

outlineOnly : bool
    Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

    See &lt;code&gt;outlineThickness&lt;/code&gt;.

outlineThickness : float or int
    Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

    If float, will be taken as fraction of the radius; if integer, will be taken as number
    of pixels.

negativeHalo : bool
    Whether to surround the particle mask with a region of negative value, which
    further promotes identifying distinct objects as grains.

haloThickness : float or int
    Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

    If float, will be taken as fraction of the radius; if integer, will be taken as number
    of pixels.

negativeInside : bool
    Whether to fill the inside of the particle mask with a negative value, which 
    further promotes identifying outlines of circles.

    Has no effect unless `outlineOnly=True`.

paddingValue : [float, `'sigmoid'`, or &lt;code&gt;None&lt;/code&gt;]
    What value to fill in for the extra padding that is added during the fft/ifft.

    &lt;code&gt;None&lt;/code&gt; leaves the value at 0.

    `'sigmoid'` will create a smooth-ish transition to 0.

    Any float value will be inserted into every point.

debug : bool
    Whether or not to plot various quantities of the calculation for inspection
</code></pre>
<ul>
<li><code>S</code>: Soft particles; shore hardness 40</li>
<li><code>M</code>: Medium particles; shore hardness 50</li>
<li>
<p><code>H</code>: Hard particles; shore hardness 60, thickness
at the end of the evaluation.</p>
<h2 id="returns">Returns</h2>
<p>chiSqr : np.ndarray[H,W]
The convolution of the kernel with the image. Larger values represent
higher likelihood that there is a particle centered there.</p>
<h2 id="references">References</h2>
<p>[1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
of Granular Materials. Chapter 2: Experimental Techniques. p.64-68.
CRC Press. <a href="https://doi.org/10.1201/b19291">https://doi.org/10.1201/b19291</a></p>
</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def circularKernelFind(singleChannelFrame, radius, fftPadding, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, paddingValue=None, debug=False):
    &#34;&#34;&#34;
    Calculate the convolution of a circular mask with an image,
    identifying likely locations of circles within the image. Adapted from
    method described in [1].

    To perform the convolution, we take the product of the fft of each the
    kernel and image, and then ifft the result to transform back to real space.
    The only peculiarity is that there can be some issues with the edges of image
    (especially if any circle centers are near the edge/off-screen) so we
    have to take care to properly pad the image and the kernel.

    Note that this method is not intended to be used as the front end for
    circle detection for real data. The method `pepe.tracking.convCircle()`
    makes use of this method to track circles, while also offering many more
    features. It is recommended to use that function unless there is a very
    specific purpose that it does not serve.

    Parameters
    ----------
    singleChannelFrame : np.ndarray[H,W]
        A single-channel image (grayscale or just one channel) within which we
        are looking to identify circular objects.

    radius : float
        The radius of circles to detect in the image.

    fftPadding : int
        The amount of padding to add to each side of the image, to prevent the
        fft from having issues. A good choice is usually 1.5 times the radius,
        though, less padding can be used if circles are not expected to often
        be located near the edges.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    paddingValue : [float, `&#39;sigmoid&#39;`, or `None`]
        What value to fill in for the extra padding that is added during the fft/ifft.

        `None` leaves the value at 0.

        `&#39;sigmoid&#39;` will create a smooth-ish transition to 0.

        Any float value will be inserted into every point.

    debug : bool
        Whether or not to plot various quantities of the calculation for inspection
- `S`: Soft particles; shore hardness 40
- `M`: Medium particles; shore hardness 50
- `H`: Hard particles; shore hardness 60, thickness
        at the end of the evaluation.

    Returns
    -------

    chiSqr : np.ndarray[H,W]
        The convolution of the kernel with the image. Larger values represent
        higher likelihood that there is a particle centered there.

    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.64-68.
    CRC Press. https://doi.org/10.1201/b19291
    &#34;&#34;&#34;

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = singleChannelFrame

    fftPadding = int(fftPadding)

    # Pad the proper image
    paddedImageArr = np.zeros((int(imageArr.shape[0] + 2*fftPadding), int(imageArr.shape[1] + 2*fftPadding)))
    paddedImageArr[fftPadding:-fftPadding,fftPadding:-fftPadding] = imageArr

    # Both dimensions will always have the same first crop index, but possibly a different second one
    cropBounds = [int(fftPadding + radius), int(-fftPadding + radius), int(-fftPadding + radius)]
    # If the fftpadding and the radius are exactly the same, we get some weird behavior
    # This happens because python can index negative values as that element from the end of
    # the array, but indexing -0 just gives 0, and so it gives you a (0,0) array.
    if cropBounds[1] &gt;= 0:
        cropBounds[1] = None
        cropBounds[2] = None

    # We have a couple options for what values to put in the padding
    if paddingValue is None or paddingValue == 0:
        # Do nothing, and leave the value at 0
        pass

    elif paddingValue == &#39;sigmoid&#39;:
        # Sigmoid gives a smoothish decay from the image to 0 at the boundaries
        # Most of the constants here are just arbitrarily chosen to make things look good
        # Top
        paddedImageArr[:fftPadding] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[fftPadding])[::-1,:] 
        # Bottom
        paddedImageArr[-fftPadding:] += np.multiply.outer(2/(1 + np.exp(np.linspace(0, 5, fftPadding))), paddedImageArr[-fftPadding-1])
        # Left
        paddedImageArr[:,:fftPadding] += np.multiply.outer(paddedImageArr[:,fftPadding], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))[:,::-1]
        # Right
        paddedImageArr[:,-fftPadding:] += np.multiply.outer(paddedImageArr[:,-fftPadding-1], 2/(1 + np.exp(np.linspace(0, 5, fftPadding))))

    else:
        # Just put a fixed value in
        paddedImageArr[:fftPadding] = paddingValue
        paddedImageArr[-fftPadding:] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,:fftPadding] = paddingValue
        paddedImageArr[fftPadding:-fftPadding,-fftPadding:] = paddingValue

    center = np.array([radius,radius])
    # To be able to properly convolute the kernel with the image, they have to
    # be the same size, so just just put our kernel into an array the same size
    # as the image (though most entries will just be zero)
    kernelArr = circularMask(paddedImageArr.shape, center, radius)[:,:,0].astype(np.float64)
   
    # If we only want the outline, we subtract another circular mask from the above one
    if outlineOnly:
        # Should be 2 if negative inside is true, 1 otherwise
        negativeInsideFactor = 1 + int(negativeInside)
        if outlineThickness &lt; 1:
            innerRadius = np.ceil((1 - outlineThickness) * radius)
        else:
            innerRadius = radius - outlineThickness
        
        kernelArr = kernelArr - negativeInsideFactor * circularMask(paddedImageArr.shape, center, innerRadius)[:,:,0].astype(np.float64)

        if negativeHalo:
            if haloThickness &lt; 1:
                haloRadius = radius + np.ceil((1 - haloThickness) * radius)
            else:
                haloRadius = radius + haloThickness

            kernelArr = 2*kernelArr - (circularMask(paddedImageArr.shape, center, haloRadius)[:,:,0].astype(np.float64) - circularMask(paddedImageArr.shape, center, radius)[:,:,0].astype(np.float64))

    elif negativeHalo:
        if haloThickness &lt; 1:
            haloRadius = np.ceil((1 + haloThickness) * radius)
        else:
            haloRadius = radius + haloThickness

        kernelArr = 2*kernelArr - circularMask(paddedImageArr.shape, center, haloRadius)[:,:,0].astype(np.float64)

    # First convolutional term
    convTerm1 = ifft2(fft2(paddedImageArr**2) * fft2(kernelArr))
    # Trim padding
    convTerm1 = convTerm1[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # Second term is pretty easy since we choose our weight function to be our
    # particle mask (and it just has 0s and 1s, so it is equal to it&#39;s square)
    convTerm2 = 2 * ifft2(fft2(paddedImageArr) * fft2(kernelArr))
    # Trim padding
    convTerm2 = convTerm2[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]]

    # For the normalization term, we want to sum all parts of the kernel that are
    # on screen (in the original image&#39;s frame) as we translate it across the image.
    originalImageMask = rectMask(paddedImageArr.shape, np.repeat(fftPadding, 2), np.array(imageArr.shape))[:,:,0]
    normalizationTerm = ifft2(fft2(originalImageMask) * fft2(kernelArr))
    # Trim padding
    normalizationTerm = np.real(normalizationTerm[cropBounds[0]:cropBounds[1],cropBounds[0]:cropBounds[2]])
    # Put everything together
    # Technically there is a +1 here, but that won&#39;t affect any minima, so we don&#39;t really care
    chiSqr = np.real((convTerm1 - convTerm2) / normalizationTerm)
    if np.min(chiSqr) &lt; 0 and np.max(chiSqr) &lt; 0:
        chiSqr = np.abs(chiSqr)

    if debug:
        fig, ax = plt.subplots(1, 4, figsize=(13,4))

        ax[0].imshow(kernelArr)
        ax[0].set_title(&#39;Kernel&#39;)

        ax[1].imshow(paddedImageArr)
        ax[1].set_title(&#39;Padded image&#39;)

        ax[2].imshow(normalizationTerm)
        ax[2].set_title(&#39;Normalization&#39;)

        ax[3].imshow(chiSqr)
        ax[3].set_title(&#39;Real-space convolution (Re)&#39;)

        fig.tight_layout()

    return chiSqr</code></pre>
</details>
</dd>
<dt id="pepe.tracking.Convolution.convCircle"><code class="name flex">
<span>def <span class="ident">convCircle</span></span>(<span>singleChannelFrame, radius, radiusTolerance=None, offscreenParticles=False, outlineOnly=False, outlineThickness=0.05, negativeHalo=False, haloThickness=0.03, negativeInside=False, peakDownsample=10, minPeakPrevalence=0.1, intensitySoftmax=1.2, intensitySoftmin=0.1, invert=False, allowOverlap=False, fitPeaks=True, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform convolution circle detection on the provided image.</p>
<p>A brief description of the technique is described below; for
a more comprehensive discussion, see [1].</p>
<p>The convolution method identifies circles in an image by convolving
a kernel (representing what a particle should look like) with the
image within which you would like to detect circles. This essentially
finds the likelihood of any particle location being the center for
such an object. By performing peak detection on this 2D quantity,
we can identify the most likely places for particles to be.</p>
<p>While this technique can be used for non-circular objects, this
implementation makes use of several simplifications/approximations
that make it suitable only for radially symmetric objects.</p>
<p>Tends to give more accurate and consistent results than the Hough
technique (see <code>pepe.tracking.houghCircle()</code>), though evaluation
times can be longer. When the radius of the circle is not well known
(with no initial guess), the Hough method should be used. That being said,
this implementation can fine tune the provided radius, but this requires
the provided value to be reasonably close to the actual value (within
~10 pixels is ideal).</p>
<p>The ability to get subpixel precision by interpolating/fitting curves to the
convolution is currently WIP, and currently the method can, at best, give results
accurate to within a single pixel.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>singleChannelFrame</code></strong> :&ensp;<code>np.uint8[H, W]</code></dt>
<dd>The frame to perform circle detection on. Should not include multiple
color channels. If it does, the channels will be averaged to form a
grayscale image.</dd>
<dt><strong><code>radius</code></strong> :&ensp;<code>float</code> or <code>[float, float]</code></dt>
<dd>
<p>The radius to look for, or min and max radii to constrain the circle
detection. If a single value is provided, a range will be constructed
around that value with the <code>radiusTolerance</code> parameter.</p>
<p>Note that this method is more sensitive to the initial guess of radius
than <code>pepe.tracking.houghCircle()</code>. Ideally, the radius should be within
~10 pixels of the true radius (or a range of radii should only be ~15 pixels wide).</p>
<p>NOTE: Varying the radius is still under development, and likely does not work that great.</p>
</dd>
<dt><strong><code>radiusTolerance</code></strong> :&ensp;<code>float</code> or <code>None</code></dt>
<dd>
<p>The half-width of the range of radii that will be tested for detecting particles.
ie. the range will be calculated as <code>[radius + radiusTolerance, radius - radiusTolerance]</code>.</p>
<p>If set to <code>None</code>, radius will be fixed at whatever value is provided via <code>radius</code> argument.</p>
<p>NOTE: Varying the radius is still under development, and likely does not work that great.</p>
</dd>
<dt><strong><code>offscreenParticles</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether or not the algorithm should look for particles whose centers are outside of
the image domain (but some parts of the particles still show up in the image).</p>
<p>This expands the padding provided to the fft/ifft calculations, so as to avoid cutting
off what might be a potential particle. As a result, a value of True will increase computation times.</p>
</dd>
<dt><strong><code>outlineOnly</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether to look for only a particle outline (True), or to look for a filled-in circle (False).</p>
<p>See <code>outlineThickness</code>.</p>
</dd>
<dt><strong><code>outlineThickness</code></strong> :&ensp;<code>float</code> or <code>int</code></dt>
<dd>
<p>Thickness of the particle outline in the kernel; only relevant if <code>outlineOnly=True</code>.</p>
<p>If float, will be taken as fraction of the radius; if integer, will be taken as number
of pixels.</p>
</dd>
<dt><strong><code>negativeHalo</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to surround the particle mask with a region of negative value, which
further promotes identifying distinct objects as grains.</dd>
<dt><strong><code>haloThickness</code></strong> :&ensp;<code>float</code> or <code>int</code></dt>
<dd>
<p>Thickness of the negative halo in the kernel; only relevant if <code>negativeHalo=True</code>.</p>
<p>If float, will be taken as fraction of the radius; if integer, will be taken as number
of pixels.</p>
</dd>
<dt><strong><code>negativeInside</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether to fill the inside of the particle mask with a negative value, which
further promotes identifying outlines of circles.</p>
<p>Has no effect unless <code>outlineOnly=True</code>.</p>
</dd>
<dt><strong><code>peakDownsample</code></strong> :&ensp;<code>int</code></dt>
<dd>
<p>The factor by which to downsample the image when performing the initial peak
detection. The final peak detection will always be performed at the original
resolution, so this should not affect the accuracy of the detected circles,
though it is possible that some particles in a densely packed system may
not be detected. False</p>
<p>Set to <code>1</code> or <code>None</code> to perform no downsampling, though this is not recommended,
as the peak finding algorithm is O(N) where N is the total number of grid points.</p>
</dd>
<dt><strong><code>minPeakPrevalence</code></strong> :&ensp;<code>float</code></dt>
<dd>
<p>The minimum prevalence (or persistence) of peaks that will be considered as
particles. Should be a float in the range <code>[0, 1.]</code>, representing the percent
of the total intensity data range that must be spanned by a feature.</p>
<p>See <code>pepe.topology.findPeaks2D()</code> for more information.</p>
</dd>
<dt><strong><code>fitPeaks</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to fit each peak in the convolution with a lorentzian
form and use that center as the location of the particle (instead of
the simple maximum point).</dd>
<dt><strong><code>intensitySoftmax</code></strong> :&ensp;<code>float</code></dt>
<dd>
<p>Value at which to cap the intensity values in the image, calculated as
this value multipled by the mean of the image.</p>
<p>Set to <code>None</code> to skip this preprocessing step.</p>
</dd>
<dt><strong><code>intensitySoftmin</code></strong> :&ensp;<code>float</code></dt>
<dd>
<p>Zero-out all values that have an intensity below this factor times the mean of
the image.</p>
<p>Set to <code>None</code> to skip this preprocessing step.</p>
</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to draw debug information on a plot.</dd>
<dt><strong><code>invert</code></strong> :&ensp;<code>bool</code></dt>
<dd>If particles appear dark on a bright background, this will invert the
image (and convolution peak finding will go from looking for maxima
to looking for minima).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>centers</code></strong> :&ensp;<code>np.ndarray[N,2]</code></dt>
<dd>The detected circles' centers.</dd>
<dt><strong><code>radii</code></strong> :&ensp;<code>np.ndarray[N]</code></dt>
<dd>The detected circles' radii.</dd>
</dl>
<h2 id="references">References</h2>
<p>[1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
of Granular Materials. Chapter 2: Experimental Techniques. p.63-68.
CRC Press. <a href="https://doi.org/10.1201/b19291">https://doi.org/10.1201/b19291</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convCircle(singleChannelFrame, radius, radiusTolerance=None, offscreenParticles=False, outlineOnly=False, outlineThickness=.05, negativeHalo=False, haloThickness=.03, negativeInside=False, peakDownsample=10, minPeakPrevalence=.1, intensitySoftmax=1.2, intensitySoftmin=.1, invert=False, allowOverlap=False, fitPeaks=True, debug=False):
    &#34;&#34;&#34;
    Perform convolution circle detection on the provided image.

    A brief description of the technique is described below; for
    a more comprehensive discussion, see [1].

    The convolution method identifies circles in an image by convolving
    a kernel (representing what a particle should look like) with the
    image within which you would like to detect circles. This essentially
    finds the likelihood of any particle location being the center for
    such an object. By performing peak detection on this 2D quantity,
    we can identify the most likely places for particles to be.

    While this technique can be used for non-circular objects, this 
    implementation makes use of several simplifications/approximations
    that make it suitable only for radially symmetric objects.

    Tends to give more accurate and consistent results than the Hough
    technique (see `pepe.tracking.houghCircle()`), though evaluation
    times can be longer. When the radius of the circle is not well known
    (with no initial guess), the Hough method should be used. That being said,
    this implementation can fine tune the provided radius, but this requires
    the provided value to be reasonably close to the actual value (within 
    ~10 pixels is ideal).

    The ability to get subpixel precision by interpolating/fitting curves to the
    convolution is currently WIP, and currently the method can, at best, give results
    accurate to within a single pixel.

    
    Parameters
    ----------
 
    singleChannelFrame : np.uint8[H, W]
        The frame to perform circle detection on. Should not include multiple
        color channels. If it does, the channels will be averaged to form a
        grayscale image.

    radius : float or [float, float]
        The radius to look for, or min and max radii to constrain the circle
        detection. If a single value is provided, a range will be constructed
        around that value with the `radiusTolerance` parameter.

        Note that this method is more sensitive to the initial guess of radius
        than `pepe.tracking.houghCircle()`. Ideally, the radius should be within
        ~10 pixels of the true radius (or a range of radii should only be ~15 pixels wide).

        NOTE: Varying the radius is still under development, and likely does not work that great.

    radiusTolerance : float or None
        The half-width of the range of radii that will be tested for detecting particles.
        ie. the range will be calculated as `[radius + radiusTolerance, radius - radiusTolerance]`.

        If set to `None`, radius will be fixed at whatever value is provided via `radius` argument.

        NOTE: Varying the radius is still under development, and likely does not work that great.

    offscreenParticles : bool
        Whether or not the algorithm should look for particles whose centers are outside of
        the image domain (but some parts of the particles still show up in the image).

        This expands the padding provided to the fft/ifft calculations, so as to avoid cutting
        off what might be a potential particle. As a result, a value of True will increase computation times.

    outlineOnly : bool
        Whether to look for only a particle outline (True), or to look for a filled-in circle (False).

        See `outlineThickness`.

    outlineThickness : float or int
        Thickness of the particle outline in the kernel; only relevant if `outlineOnly=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeHalo : bool
        Whether to surround the particle mask with a region of negative value, which
        further promotes identifying distinct objects as grains.

    haloThickness : float or int
        Thickness of the negative halo in the kernel; only relevant if `negativeHalo=True`.

        If float, will be taken as fraction of the radius; if integer, will be taken as number
        of pixels.

    negativeInside : bool
        Whether to fill the inside of the particle mask with a negative value, which 
        further promotes identifying outlines of circles.

        Has no effect unless `outlineOnly=True`.

    peakDownsample : int
        The factor by which to downsample the image when performing the initial peak
        detection. The final peak detection will always be performed at the original
        resolution, so this should not affect the accuracy of the detected circles,
        though it is possible that some particles in a densely packed system may
        not be detected. False

        Set to `1` or `None` to perform no downsampling, though this is not recommended,
        as the peak finding algorithm is O(N) where N is the total number of grid points.

    minPeakPrevalence : float
        The minimum prevalence (or persistence) of peaks that will be considered as
        particles. Should be a float in the range `[0, 1.]`, representing the percent
        of the total intensity data range that must be spanned by a feature.

        See `pepe.topology.findPeaks2D()` for more information.

    fitPeaks : bool
        Whether or not to fit each peak in the convolution with a lorentzian
        form and use that center as the location of the particle (instead of
        the simple maximum point).

    intensitySoftmax : float
        Value at which to cap the intensity values in the image, calculated as
        this value multipled by the mean of the image.

        Set to `None` to skip this preprocessing step.

    intensitySoftmin : float
        Zero-out all values that have an intensity below this factor times the mean of
        the image.

        Set to `None` to skip this preprocessing step.
        
    debug : bool
        Whether or not to draw debug information on a plot. 

    invert : bool
        If particles appear dark on a bright background, this will invert the
        image (and convolution peak finding will go from looking for maxima
        to looking for minima).
   
    Returns
    -------

    centers : np.ndarray[N,2]
        The detected circles&#39; centers.

    radii : np.ndarray[N]
        The detected circles&#39; radii.


    References
    ----------

    [1] Franklin, S. V., &amp; Shattuck, M. D. (Eds.). (2016). Handbook
    of Granular Materials. Chapter 2: Experimental Techniques. p.63-68.
    CRC Press. https://doi.org/10.1201/b19291

    &#34;&#34;&#34;

    # General housekeeping of arguments, see if we need to parse anything
    if offscreenParticles:
        paddingFactor = 2.
    else:
        paddingFactor = 1.1

    if peakDownsample is None:
        peakDownsample = 1
 
    # Check if we are given a range of radii or just a single value
    possibleRadii = None

    if hasattr(radius, &#39;__iter__&#39;):
        if len(radius) == 2 and radius[0] &lt; radius[1]:
           possibleRadii = np.arange(radius[0], radius[1]+1)
        else:
            raise Exception(f&#39;Invalid radius provided to convCircle()!\n Expected scalar or [min, max], but got {radius}!&#39;)
    elif radiusTolerance is not None:
        # Use the tolerance
        possibleRadii = np.arange(radius - radiusTolerance, radius + radiusTolerance)
    else:
        # Just the single value
        possibleRadii = np.array([radius])

    # Start with just the mean of the possible radii options
    initialRadius = np.mean(possibleRadii)

    if singleChannelFrame.ndim &gt; 2:
        imageArr = np.mean(singleChannelFrame, axis=-1)
    else:
        imageArr = np.copy(singleChannelFrame)
            
    if invert:
        imageArr = np.max(imageArr) - imageArr

    if intensitySoftmax is not None:
        softmax = np.mean(imageArr) * intensitySoftmax
        if not invert:
            imageArr[imageArr &gt;= softmax] = softmax
        #else:
        #    imageArr[255 - imageArr &gt;= softmax] = softmax

    if intensitySoftmin is not None:
        softmin = np.mean(imageArr) * intensitySoftmin
        if not invert:
            imageArr[imageArr &lt;= softmin] = 0
        #else:
        #    imageArr[255 - imageArr &lt;= softmin] = 0

    # Calculate convolution
    convArr = circularKernelFind(imageArr, initialRadius, fftPadding=int(initialRadius*paddingFactor),
                                 outlineOnly=outlineOnly, outlineThickness=outlineThickness,
                                 negativeHalo=negativeHalo, haloThickness=haloThickness,
                                 negativeInside=negativeInside, debug=debug)

    if debug:
        plt.show()

    # Downsample data by 5-10x and run peak detection
    downsampledConvArr = cv2.resize(cv2.blur(convArr, (peakDownsample,peakDownsample)), (0,0),
                                    fx=1/peakDownsample, fy=1/peakDownsample, interpolation=cv2.INTER_CUBIC)

    peakPositions, peakPrevalences = findPeaks2D(downsampledConvArr, minPeakPrevalence=minPeakPrevalence)

    lorentzPositions = np.zeros((len(peakPositions), 2))
    cleanedConvArr = np.zeros_like(convArr)

    # We have the option to fit lorentzian peaks to each maximum in the convolution
    # matrix, or we can just take the peak positions as they are
    if fitPeaks:
        def objectiveFunction(params, localImage):
            # Create a small grid across the area
            Y,X = np.ogrid[:localImage.shape[0], :localImage.shape[1]]
            Y += int(params[&#34;center_y&#34;] - localImage.shape[0]/2)
            X += int(params[&#34;center_x&#34;] - localImage.shape[1]/2)

            lorentzArr = lorentzian([Y,X], [params[&#34;center_y&#34;], params[&#34;center_x&#34;]], params[&#34;width&#34;], params[&#34;amp&#34;], params[&#34;offset&#34;])
            
            return np.sum((localImage - lorentzArr)**2)

        # Now we fit an appropriate function to each peak to see if we can refine the center
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            imagePadding = int(np.mean(possibleRadii))
            # Crop out the small area of the image around the peak
            localConv = convArr[max(upsampledPosition[0]-imagePadding, 0):min(upsampledPosition[0]+imagePadding,convArr.shape[0]-1), max(upsampledPosition[1]-imagePadding, 0):min(upsampledPosition[1]+imagePadding, convArr.shape[1]-1)]


            #plt.imshow(localConv)
            #plt.show()
            # Now setup a fit to this function
            params = Parameters()

            params.add(&#39;center_y&#39;, value=localConv.shape[0]/2, vary=True)
            params.add(&#39;center_x&#39;, value=localConv.shape[1]/2, vary=True)
            params.add(&#39;width&#39;, value=imagePadding/2, vary=False)
            params.add(&#39;amp&#39;, value=np.max(localConv)-np.min(localConv), vary=False)
            params.add(&#39;offset&#39;, value=np.min(localConv), vary=False)
        
            result = minimize(objectiveFunction, params, args=[localConv], method=&#39;nelder&#39;, max_nfev=10000)
            
            if result is not None:
                lorentzPositions[i,0] = upsampledPosition[0] - localConv.shape[0]/2 + result.params[&#34;center_y&#34;]
                lorentzPositions[i,1] = upsampledPosition[1] - localConv.shape[1]/2 + result.params[&#34;center_x&#34;]

                Y,X = np.ogrid[:convArr.shape[0], :convArr.shape[1]]
                cleanedConvArr += lorentzian([Y,X], lorentzPositions[i], result.params[&#34;width&#34;], result.params[&#34;amp&#34;], result.params[&#34;offset&#34;])

            else:
                lorentzPositions[i] = upsampledPosition

    else:
        for i in range(len(peakPositions)):
            upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            lorentzPositions[i] = upsampledPosition

    # Look around each peak to find the real peak in the full-resolution image
    refinedPeakPositions = []
    refinedRadii = []

    localPadding = int(peakDownsample*1.5)
    for i in range(len(peakPositions)):
        # We want to vary the radius here as well, so we can maybe get a slightly more accurate result.
        # Note that it is much more efficient to perform the kernel finding on a small image many times
        # than to work on a large image just a few times. So we recalculate the kernel finding for each
        # radii for each peak.
        # TODO: This part is still WIP, because it doens&#39;t quite work correctly
        if len(possibleRadii) &gt; 1:
            maximumValues = np.zeros(len(possibleRadii))
            maximumPositions = np.zeros((len(possibleRadii), 2))

            #upsampledPosition = np.array([peakPositions[i][0]*peakDownsample, peakPositions[i][1]*peakDownsample])
            upsampledPosition = np.int16(lorentzPositions[i])
            for j in range(len(possibleRadii)):
                # This is the point in the real image (not the conv arr)
                imagePadding = int(possibleRadii[j])
                # Crop out the small area of the image that we are working with
                localImage = imageArr[max(upsampledPosition[0]-imagePadding, 0):min(upsampledPosition[0]+imagePadding,imageArr.shape[0]-1),max(upsampledPosition[1]-imagePadding, 0):min(upsampledPosition[1]+imagePadding, imageArr.shape[1]-1)]

                # Perform another convolution
                # Don&#39;t need as much padding for this one, since we are quite sure the particle is somewhere
                # near the center
                localConvPadding = int(possibleRadii[j])
                localConvArr = circularKernelFind(localImage, possibleRadii[j], fftPadding=localConvPadding,
                                                  outlineOnly=outlineOnly, outlineThickness=outlineThickness,
                                                  negativeHalo=negativeHalo, haloThickness=haloThickness,
                                                  negativeInside=negativeInside, debug=False)
                # Required if you set debug=True in above line
                #plt.show()

                # Add a *very* small weighting that favors circles closer to the center of the
                # image. This is needed because otherwise the algorithm may place circles more
                # offscreen than they actually are, because it would mean fewer pixels are included
                # (since some are cropped off)
                #Y = np.arange(localImage.shape[0]).reshape((localImage.shape[0], 1)) # Column vector
                #X = np.arange(localImage.shape[1]).reshape((1, localImage.shape[1])) # Row vector
                #localConvArr += 1e-3*np.exp(- ( (Y - localImage.shape[0]/2)**2 + (X - localImage.shape[1]/2)**2 ) / max(localImage.shape))

                # Now setup a fit to this function
                params = Parameters()

                params.add(&#39;center_y&#39;, value=localImage.shape[0]/2, vary=True)
                params.add(&#39;center_x&#39;, value=localImage.shape[1]/2, vary=True)
                params.add(&#39;width&#39;, value=imagePadding, vary=True)
                params.add(&#39;amp&#39;, value=np.max(localConvArr)/2, vary=True)
                params.add(&#39;offset&#39;, value=np.mean(localConvArr), vary=True)
                
                try:
                    result = minimize(objectiveFunction, params, args=[localConvArr], method=&#39;nelder&#39;, max_nfev=1000)
                except:
                    result = None
                
                if result is not None:
                    realLocalMax = np.array([int(result.params[&#34;center_y&#34;]), int(result.params[&#34;center_x&#34;])])
                else:
                    realLocalMax = np.zeros(2)

                #realLocalMax = np.unravel_index(np.argmax(localConvArr.flatten()), localConvArr.shape)
                # We want to convert these back to real-space coordinates here
                #maximumPositions[j] = upsampledPosition - realLocalMax - np.repeat(localConvPadding, 2)
                maximumPositions[j,0] = upsampledPosition[0] - localConvArr.shape[0]/2 + realLocalMax[0]
                maximumPositions[j,1] = upsampledPosition[1] - localConvArr.shape[1]/2 + realLocalMax[1]

                # Need to convert to int16 since we might have negative values
                pMask = circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j])[:,:,0].astype(np.int16)

                # The next couple if statements are for only doing an outline, adding a halo, removing the center, etc.
                # If we only want the outline, we subtract another circular mask from the above one
                if outlineOnly:
                    # Should be 2 if negative inside is true, 1 otherwise
                    negativeInsideFactor = 1 + int(negativeInside)
                    if outlineThickness &lt; 1:
                        innerRadius = np.ceil((1 - outlineThickness) * possibleRadii[j])
                    else:
                        innerRadius = possibleRadii[j] - outlineThickness
                        pMask -= negativeInsideFactor * circularMask(singleChannelFrame.shape, maximumPositions[j], innerRadius)[:,:,0]

                    if negativeHalo:
                        pMask = 2*pMask - (circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j]+2)[:,:,0].astype(np.int16) - circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j])[:,:,0].astype(np.int16))

                elif negativeHalo:
                    pMask = 2*pMask - circularMask(singleChannelFrame.shape, maximumPositions[j], possibleRadii[j]+2)[:,:,0].astype(np.int16)


                if np.sum(pMask) == 0:
                    maximumValues[j] = 0
                else:
                    maximumValues[j] = np.sum(singleChannelFrame * pMask) / np.sum(pMask)
           
            

            # Noise can cause some slight variations in the maximum values making different
            # radii give different maximum values, when they should give actually the same
            # value (and then the largest one should be taken). We fix this by rounding
            # after multiply by a large number. .5e3 was chosen by experimenting

            maximumValues = [int(m*1e2) if not np.isnan(m) else 0 for m in maximumValues]

            #plt.plot(possibleRadii, maximumValues)
            #plt.show()

            # Now save whichever on had the largest signal
            # We want to sort the list backwards, because we want the largest possible radius
            # that also gives the best value. If the radius is smaller than the actual one, you
            # can end up with the same exact maximum value, since you are just cutting off extra
            # parts of the circle.
            refinedPeakPositions.append(tuple(maximumPositions[::-1][np.argmax(maximumValues[::-1])]))
            refinedRadii.append(possibleRadii[::-1][np.argmax(maximumValues[::-1])])

        else:
            # Position of the peaks in the convolution image (NOT the real image)
            upsampledPosition = np.int16(lorentzPositions[i])
            
            # We don&#39;t need to refine if we fit a peak, since that already did refine the
            # position
            if fitPeaks:
                refinementOffset = 0

            else:
                # This just looks long because my naming is a little verbose
                # + we also have to make sure we don&#39;t accidentally go off of the image
                localRegion = convArr[max(upsampledPosition[0]-localPadding, 0):min(upsampledPosition[0]+localPadding,convArr.shape[0]-1),max(upsampledPosition[1]-localPadding, 0):min(upsampledPosition[1]+localPadding, convArr.shape[1]-1)]
                # Find maximum intensity in small region around that position
                realLocalMax = np.unravel_index(np.argmax(localRegion.flatten()), localRegion.shape)
                # This is relative to the small region we just created, so we have to subtract off the bounds
                # eg. if this local max was found to be in the center of the local image, that would mean
                # that the original upsampled position was correct.
                refinementOffset = realLocalMax - np.repeat(localPadding, 2)

            # Now put everything together the coordinates of the circle in the original image
            refinedPeakPositions.append(tuple(upsampledPosition + refinementOffset))
            refinedRadii.append(initialRadius)


    # Now we (optionally) remove overlapping particles
    if not allowOverlap:
        # Calculate the contact matrix
        # negative contact padding because we don&#39;t want to remove particles that are
        # good but just close to each other
        adjMat = adjacencyMatrix(refinedPeakPositions, refinedRadii, contactPadding=-int(np.mean(refinedRadii)/10)) - np.eye(len(refinedPeakPositions))

        # Locate all of the particles that are overlapping
        overlappingParticles = np.array([i for i in range(len(refinedPeakPositions)) if np.sum(adjMat[i,:]) &gt; 0])

        # Now find how good of detections each of these is, and order them from worst to best.
        particleScores = np.zeros(len(overlappingParticles))
        for i in range(len(particleScores)):
            # Need to convert to int16 since we might have negative values
            pMask = circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i])[:,:,0].astype(np.int16)

            # The next couple if statements are for only doing an outline, adding a halo, removing the center, etc.
            # If we only want the outline, we subtract another circular mask from the above one
            if outlineOnly:
                # Should be 2 if negative inside is true, 1 otherwise
                negativeInsideFactor = 1 + int(negativeInside)
                if outlineThickness &lt; 1:
                    innerRadius = np.ceil((1 - outlineThickness) * refinedRadii[i])
                else:
                    innerRadius = refinedRadii[i] - outlineThickness
                    pMask -= negativeInsideFactor * circularMask(singleChannelFrame.shape, refinedPeakPositions[i], innerRadius)[:,:,0]

                if negativeHalo:
                    pMask = 2*pMask - (circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i]+2)[:,:,0].astype(np.int16) - circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i])[:,:,0].astype(np.int16))

            elif negativeHalo:
                pMask = 2*pMask - circularMask(singleChannelFrame.shape, refinedPeakPositions[i], refinedRadii[i]+2)[:,:,0].astype(np.int16)

            if np.sum(pMask) &gt; 0:
                # I square-root the mask sum so that the particles at the edge don&#39;t
                # always win out against actual particles
                # TODO: This still doesn&#39;t give priority to particles on screen;
                # need to figure out a way to do that
                particleScores[i] = np.sum(singleChannelFrame * pMask) / np.sqrt(np.sum(pMask))
            else:
                particleScores[i] = 0 

        # Sort according to worst scores
        order = np.argsort(particleScores)[::-1]
        overlappingParticles = overlappingParticles[order]

        # Now we start removing the particles with the worst scores until we no longer have overlap
        index = 0
        while np.sum(adjMat) &gt; 0:
            adjMat[overlappingParticles[index],:] = 0
            adjMat[:,overlappingParticles[index]] = 0
            refinedPeakPositions[overlappingParticles[index]] = None
            refinedRadii[overlappingParticles[index]] = None

            index += 1

           
        # Now remove all of the None values we put in
        refinedPeakPositions = [rpp for rpp in refinedPeakPositions if rpp is not None]
        refinedRadii = [rr for rr in refinedRadii if rr is not None]


    # Debug option
    if debug:
        fig = plt.figure(figsize=(12,4))

        ax1 = fig.add_subplot(1, 3, 1, projection=&#39;3d&#39;)
        ax1.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), convArr, cmap=plt.cm.jet)
        ax1.set_title(&#39;Convolution&#39;)

        ax2 = fig.add_subplot(1, 3, 2, projection=&#39;3d&#39;)
        ax2.plot_surface(np.arange(convArr.shape[1]),
                        np.vstack(np.arange(convArr.shape[0])), cleanedConvArr, cmap=plt.cm.jet)
        ax2.set_title(&#39;Cleaned Convolution&#39;)

        ax3 = fig.add_subplot(1, 3, 3)
        ax3.imshow(singleChannelFrame)
        ax3.set_title(&#39;Detected circles&#39;)
        for i in range(len(refinedPeakPositions)):
            c = plt.Circle(refinedPeakPositions[i][::-1], refinedRadii[i], color=&#39;red&#39;, fill=False, linewidth=1)
            ax3.add_artist(c)

        fig.tight_layout()

    return np.array(refinedPeakPositions), np.array(refinedRadii)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pepe.tracking" href="index.html">pepe.tracking</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pepe.tracking.Convolution.circularKernelFind" href="#pepe.tracking.Convolution.circularKernelFind">circularKernelFind</a></code></li>
<li><code><a title="pepe.tracking.Convolution.convCircle" href="#pepe.tracking.Convolution.convCircle">convCircle</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>