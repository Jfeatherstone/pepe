<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pepe.topology.Clustering API documentation</title>
<meta name="description" content="These methods aren&#39;t really &#39;topological&#39;, but I think this is
still the most apt place to put this code." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pepe.topology.Clustering</code></h1>
</header>
<section id="section-intro">
<p>These methods aren't really 'topological', but I think this is
still the most apt place to put this code.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
These methods aren&#39;t really &#39;topological&#39;, but I think this is
still the most apt place to put this code.
&#34;&#34;&#34;

import numpy as np
from scipy.spatial import KDTree

import matplotlib.pyplot as plt

def spatialClusterLabels(points, l=.001, randomize=False, wrapPoints=None):
    &#34;&#34;&#34;
    Partition a set of points in clusters, and return the
    cluster label for each point.

    Method is very simplistic: the neighbors (points within
    a threshold distance) of a point are added to the same
    cluster, and the process is repeated until no points
    remain. This means that the size of clusters can be
    larger than this distance threshold (eg. think of a
    chain of points).

    Usage
    -----
    The partitioning process is done by iterating through all
    of the provided points, and identifying their neighbors. As
    such, this process can vary based on the order the points are
    provided in. There are two different ways to deal with this
    while still maintaining reproducible results.

    First, you can order the points in some meaningful way, with
    the more important (whatever that means for your case) points
    coming first. This should be done before calling this partitioning
    method. Second, you can use the `randomize=True` kwarg, and rely
    on the fact that this should lead to a statistically sound
    calculation.

    As an example, consider identifying clusters of points above some
    threshold (whether in brightness, \(G^2\), or whatever else) in
    an image. For the first approach, you might order the points by the
    magnitude of the parameter you are thresholding with respect to, since
    eg. it could be assumed that very bright points are more important
    than points that are just barely above the threshold. For the second
    approach, you might perform the clustering process M times to get
    a statistical ensemble, and then resolve the individual partitionings
    into a single combined one.

    Parameters
    ----------
    points : numpy.ndarray[N,d]
        Array of N points in d-dimensions

    l : float
        Distance threshold to consider two points as being in the
        same cluster. Given as fraction of the total system size.

    randomize : bool
        The clustering processes is dependent on the order of
        the points; if `randomize=True`, the provided array will
        be indexed in a random order, otherwise it will be accessed
        exactly as provided.

    wrapPoints : numpy.ndarray[d] or float or None
        If the space is periodic, the size of each dimension. If
        a single value is given, this will be used for all dimensions.

        If None, no periodicity is assumed.

        Can have a mix of periodic and non-periodic dimensions,
        eg. spherical coordinates should have:
            `wrapPoints=[None, 2*np.pi, np.pi]`
        
    Returns
    -------
    labels : numpy.ndarray[N]
        Array of N labels (integers) denoting cluster
        assignment. Total number of clusters will be `max(labels)+1`.
    &#34;&#34;&#34;
    d = np.shape(points)[-1]
    
    systemLengthScale = np.sqrt(np.sum([(np.max(points[:,i]) - np.min(points[:,i]))**2 for i in range(d)]))
    threshold = l*systemLengthScale
   
    # Generate a kd-tree
    # If we have a periodic space, we need to clean and pass that
    # information to the kd tree
    if hasattr(wrapPoints, &#39;__iter__&#39;):
        assert len(wrapPoints) == d, f&#39;Wrap dimensions ({len(wrapPoints)}) do not match the dimension of the data ({d})!&#39;

        boxSize = np.array([wrapPoints[i] if wrapPoints[i] is not None else np.max(points[:,i])*10 for i in range(d)])
        kdTree = KDTree(points, boxsize=boxSize)

    elif wrapPoints is not None:
        boxSize = np.repeat(wrapPoints, d)
        kdTree = KDTree(points, boxsize=boxSize)
    
    else:
        kdTree = KDTree(points)

    pointsList = points.tolist()

    randomOrder = np.arange(len(pointsList))

    if randomize:
        np.random.shuffle(randomOrder)
    
    labels = np.zeros(len(pointsList)) - 1
    labelsToMerge = []
    
    i = 0
    
    while len(np.where(labels == -1)[0]) &gt; 0:
        # Grab a point, if it doesn&#39;t have a group already, create a new one
        if labels[randomOrder[i]] == -1:
            labels[randomOrder[i]] = np.max(labels)+1
        p = pointsList[randomOrder[i]]

        # Find its neighbors
        neighbors = kdTree.query_ball_point(p, r=threshold)

        # neighorLabels = [labels[n] for n in neighors]
        # uniqueNeighborLabels = np.unique(neighborLabels)
        # if len(uniqueNeighborLabels) == 1:
        #     # If all are unlabeled
        #     if uniqueNeighborLabels[0] == -1:
        #         # Create a new group
        #         labels[randomOrder[i]] = np.max(labels)+1

        #     # All are already in another group
        #     else:
        #         # Assign this point to that group as well
        #         labels[randomOrder[i]] = uniqueNeighborLabels[0]
        
        # Assign all of them to be the same group
        for index in neighbors:
            if index == randomOrder[i]:
                continue
                
            # If they already have a label, we will eventually want to merge the labels
            if labels[index] &gt;= 0 and labels[index] != labels[randomOrder[i]]:
                # See if this is already in a merge group
                inGroup = False
                for j in range(len(labelsToMerge)):
                    # If it is already going to be merged, add the
                    # new label to this group
                    if labels[index] in labelsToMerge[j]:
                        inGroup = True
                        # If the new label is not in the merge group, add it
                        if not labels[randomOrder[i]] in labelsToMerge[j]:
                            labelsToMerge[j].append(labels[randomOrder[i]])
                            
                        break
                # If we aren&#39;t in a merge group, we should create
                # a new one
                if not inGroup:
                    labelsToMerge.append([labels[index], labels[randomOrder[i]]])
                    
            elif labels[index] == -1:
                labels[index] = labels[randomOrder[i]]
            
        i += 1

    mergedLabels = np.zeros_like(labels) - 1
    
    # Now we have to sort out merged clusters
    labelSets = []
    for i in range(int(np.max(labels))+1):
        # Generate a list of all of the labels that are identified together
        # including this value of i
        allLabels = [i]
        for j in range(len(labelsToMerge)):
            if i in labelsToMerge[j]:
                allLabels += labelsToMerge[j]

        # sort so that way we can do a unique check to remove
        # duplicates
        allLabels = sorted(np.unique(allLabels))
        # Python may automatically collapse the list if it is of length 1,
        # which we don&#39;t want.
        labelSets.append([allLabels] if len(allLabels) == 1 else allLabels)

    # Remove duplicate sets, creating disjoint sets of labels
    uniqueSets = np.unique(np.array(labelSets, list))

    # If there are no overlaps, then this above operation will
    # flatten the array to be one dimensional. We can&#39;t do anything
    # about that, except to check if it is the case. The good news is
    # that if this is the case, then we already have disjoint sets
    # and we can just immediately return our label array
    if len(np.shape(uniqueSets)) == 1:
        return labels

    # Relabel things with the new disjoint sets
    mergedLabels = np.zeros_like(labels)

    # TODO: Probably a much better way to do this
    for i in range(len(pointsList)):
        for j in range(len(uniqueSets)):
            if labels[i] in uniqueSets[j]:
                mergedLabels[i] = j
                break

    return mergedLabels

def spatialClusterCenters(points, l=.001, randomize=False, wrapPoints=None, pointWeights=None, return_weights=False):
    &#34;&#34;&#34;
    Partition a set of points in clusters, and compute the
    center of each cluster.

    Generates clusters using `pepe.topology.spatialClusterLabels()`; see
    this method for more information.

    Parameters
    ----------
    points : numpy.ndarray[N,d]
        Array of N points in d-dimensions

    l : float
        Distance threshold to consider two points as being in the
        same cluster. Given as fraction of the total system size.

    randomize : bool
        The clustering processes is dependent on the order of
        the points; if `randomOrder=True`, the provided array will
        be indexed in a random order, otherwise it will be accessed
        exactly as provided. 
        
        See documentation for `pepe.topology.spatialClusterLabels()`.

    wrapPoints : numpy.ndarray[d] or float or None
        If the space is periodic, the size of each dimension. If
        a single value is given, this will be used for all dimensions.

        If None, no periodicity is assumed.

        Can have a mix of periodic and non-periodic dimensions,
        eg. spherical coordinates should have:
            `wrapPoints=[None, 2*np.pi, np.pi]`

    pointWeights : numpy.ndarray[N] or None
        An array of weights to be used in finding the center of
        mass of each cluster. If `None`, every point will be
        weighted the same.

    return_weights : bool
        Whether to return the weight -- defined as the fraction of
        points included in that cluster -- alongside the centers.

        If a weight is given for each point using `pointWeights`, this
        will be used in calculating the weight of a cluster.
        
    Returns
    -------
    centers : numpy.ndarray[N, d]
        Array of N points in d-dimensions representing the detected
        clusters in the system.

    weights : numpy.ndarray[N]
        Array of weights -- defined as fraction of all points included
        in each cluster -- for each cluster. Only returned if
        `return_weights=True`.

    &#34;&#34;&#34;
    labels = spatialClusterLabels(points, l=l, randomize=randomize, wrapPoints=wrapPoints)
    numLabels = int(np.max(labels))+1

    if hasattr(pointWeights, &#39;__iter__&#39;):
        individualWeights = pointWeights
    else:
        individualWeights = np.ones_like(labels)

    # Compute the center of each cluster
    weights = np.zeros(numLabels)
    centers = np.zeros((numLabels, np.shape(points)[-1]))
     
    # If our data is periodic, we can&#39;t just take the average of
    # the positions, we have to account for the possibility
    # that a cluster wraps around a boundary.
    if hasattr(wrapPoints, &#39;__iter__&#39;) or wrapPoints is not None:
        for i in range(numLabels):
            indices = np.where(labels == i)[0]
            # We can check if we have a discontinuous jump by looking at the
            # sort changes in each dimension. If there is a jump that is larger
            # than half of the dimension size, this means that boundary needs to
            # be factored in.
            boundaryCrosses = [False]*np.shape(points)[-1]
            divideCenters = [np.nan]*np.shape(points)[-1]
            for j in range(np.shape(points)[-1]):
                oneDimPoints = np.sort(points[indices,j])
                diffArr = oneDimPoints[1:] - oneDimPoints[:-1]
                maxIndex = np.argmax(np.abs(diffArr))
                boundaryCrosses[j] = np.abs(diffArr[maxIndex]) &gt; wrapPoints[j]/2
                # Record where the center of the gap between the two sides is
                divideCenters[j] = (oneDimPoints[maxIndex] + oneDimPoints[maxIndex+1])/2

            # Now we adjust the axes that were identified
            # Not the best naming but this array contains points that
            # are wrapped whereas wrapPoints contains the actual points
            # at which the space wraps around itself...
            wrappedPoints = np.array(points)[indices]
            for j in np.where(boundaryCrosses)[0]:
                # We have to find all of the points on one side of the wrap
                preWrapIndices = np.where(wrappedPoints[:,j] &lt; divideCenters[j])
                # Move them to the other side of the wrap
                wrappedPoints[preWrapIndices,j] += wrapPoints[j]

            # Take the weighted average
            centers[i] = np.average(wrappedPoints, weights=individualWeights[indices], axis=0)
            weights[i] = np.sum(individualWeights[indices]) / np.sum(individualWeights)

            # Adjust in case we ended up outside on the wrong side
            # of the boundary
            # TODO
            axisNeedsAdjusting = (centers[i] / wrapPoints) &gt; 1
            for j in np.where(axisNeedsAdjusting)[0]:
                centers[i][j] -= wrapPoints[j]

    else:
        for i in range(numLabels):
            indices = np.where(labels == i)
            # Weighted average
            centers[i] = np.average(np.array(points)[indices], weights=individualWeights[indices], axis=0)
            weights[i] = np.sum(individualWeights[indices]) / np.sum(individualWeights)

    order = np.argsort(weights)[::-1]
    centers = centers[order]
    weights = weights[order]
    
    if return_weights:
        return centers, weights
        
    return centers</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pepe.topology.Clustering.spatialClusterCenters"><code class="name flex">
<span>def <span class="ident">spatialClusterCenters</span></span>(<span>points, l=0.001, randomize=False, wrapPoints=None, pointWeights=None, return_weights=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Partition a set of points in clusters, and compute the
center of each cluster.</p>
<p>Generates clusters using <code>pepe.topology.spatialClusterLabels()</code>; see
this method for more information.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>points</code></strong> :&ensp;<code>numpy.ndarray[N,d]</code></dt>
<dd>Array of N points in d-dimensions</dd>
<dt><strong><code>l</code></strong> :&ensp;<code>float</code></dt>
<dd>Distance threshold to consider two points as being in the
same cluster. Given as fraction of the total system size.</dd>
<dt><strong><code>randomize</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>The clustering processes is dependent on the order of
the points; if <code>randomOrder=True</code>, the provided array will
be indexed in a random order, otherwise it will be accessed
exactly as provided. </p>
<p>See documentation for <code>pepe.topology.spatialClusterLabels()</code>.</p>
</dd>
<dt><strong><code>wrapPoints</code></strong> :&ensp;<code>numpy.ndarray[d]</code> or <code>float</code> or <code>None</code></dt>
<dd>
<p>If the space is periodic, the size of each dimension. If
a single value is given, this will be used for all dimensions.</p>
<p>If None, no periodicity is assumed.</p>
<p>Can have a mix of periodic and non-periodic dimensions,
eg. spherical coordinates should have:
<code>wrapPoints=[None, 2*np.pi, np.pi]</code></p>
</dd>
<dt><strong><code>pointWeights</code></strong> :&ensp;<code>numpy.ndarray[N]</code> or <code>None</code></dt>
<dd>An array of weights to be used in finding the center of
mass of each cluster. If <code>None</code>, every point will be
weighted the same.</dd>
<dt><strong><code>return_weights</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>Whether to return the weight &ndash; defined as the fraction of
points included in that cluster &ndash; alongside the centers.</p>
<p>If a weight is given for each point using <code>pointWeights</code>, this
will be used in calculating the weight of a cluster.</p>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>centers</code></strong> :&ensp;<code>numpy.ndarray[N, d]</code></dt>
<dd>Array of N points in d-dimensions representing the detected
clusters in the system.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>numpy.ndarray[N]</code></dt>
<dd>Array of weights &ndash; defined as fraction of all points included
in each cluster &ndash; for each cluster. Only returned if
<code>return_weights=True</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def spatialClusterCenters(points, l=.001, randomize=False, wrapPoints=None, pointWeights=None, return_weights=False):
    &#34;&#34;&#34;
    Partition a set of points in clusters, and compute the
    center of each cluster.

    Generates clusters using `pepe.topology.spatialClusterLabels()`; see
    this method for more information.

    Parameters
    ----------
    points : numpy.ndarray[N,d]
        Array of N points in d-dimensions

    l : float
        Distance threshold to consider two points as being in the
        same cluster. Given as fraction of the total system size.

    randomize : bool
        The clustering processes is dependent on the order of
        the points; if `randomOrder=True`, the provided array will
        be indexed in a random order, otherwise it will be accessed
        exactly as provided. 
        
        See documentation for `pepe.topology.spatialClusterLabels()`.

    wrapPoints : numpy.ndarray[d] or float or None
        If the space is periodic, the size of each dimension. If
        a single value is given, this will be used for all dimensions.

        If None, no periodicity is assumed.

        Can have a mix of periodic and non-periodic dimensions,
        eg. spherical coordinates should have:
            `wrapPoints=[None, 2*np.pi, np.pi]`

    pointWeights : numpy.ndarray[N] or None
        An array of weights to be used in finding the center of
        mass of each cluster. If `None`, every point will be
        weighted the same.

    return_weights : bool
        Whether to return the weight -- defined as the fraction of
        points included in that cluster -- alongside the centers.

        If a weight is given for each point using `pointWeights`, this
        will be used in calculating the weight of a cluster.
        
    Returns
    -------
    centers : numpy.ndarray[N, d]
        Array of N points in d-dimensions representing the detected
        clusters in the system.

    weights : numpy.ndarray[N]
        Array of weights -- defined as fraction of all points included
        in each cluster -- for each cluster. Only returned if
        `return_weights=True`.

    &#34;&#34;&#34;
    labels = spatialClusterLabels(points, l=l, randomize=randomize, wrapPoints=wrapPoints)
    numLabels = int(np.max(labels))+1

    if hasattr(pointWeights, &#39;__iter__&#39;):
        individualWeights = pointWeights
    else:
        individualWeights = np.ones_like(labels)

    # Compute the center of each cluster
    weights = np.zeros(numLabels)
    centers = np.zeros((numLabels, np.shape(points)[-1]))
     
    # If our data is periodic, we can&#39;t just take the average of
    # the positions, we have to account for the possibility
    # that a cluster wraps around a boundary.
    if hasattr(wrapPoints, &#39;__iter__&#39;) or wrapPoints is not None:
        for i in range(numLabels):
            indices = np.where(labels == i)[0]
            # We can check if we have a discontinuous jump by looking at the
            # sort changes in each dimension. If there is a jump that is larger
            # than half of the dimension size, this means that boundary needs to
            # be factored in.
            boundaryCrosses = [False]*np.shape(points)[-1]
            divideCenters = [np.nan]*np.shape(points)[-1]
            for j in range(np.shape(points)[-1]):
                oneDimPoints = np.sort(points[indices,j])
                diffArr = oneDimPoints[1:] - oneDimPoints[:-1]
                maxIndex = np.argmax(np.abs(diffArr))
                boundaryCrosses[j] = np.abs(diffArr[maxIndex]) &gt; wrapPoints[j]/2
                # Record where the center of the gap between the two sides is
                divideCenters[j] = (oneDimPoints[maxIndex] + oneDimPoints[maxIndex+1])/2

            # Now we adjust the axes that were identified
            # Not the best naming but this array contains points that
            # are wrapped whereas wrapPoints contains the actual points
            # at which the space wraps around itself...
            wrappedPoints = np.array(points)[indices]
            for j in np.where(boundaryCrosses)[0]:
                # We have to find all of the points on one side of the wrap
                preWrapIndices = np.where(wrappedPoints[:,j] &lt; divideCenters[j])
                # Move them to the other side of the wrap
                wrappedPoints[preWrapIndices,j] += wrapPoints[j]

            # Take the weighted average
            centers[i] = np.average(wrappedPoints, weights=individualWeights[indices], axis=0)
            weights[i] = np.sum(individualWeights[indices]) / np.sum(individualWeights)

            # Adjust in case we ended up outside on the wrong side
            # of the boundary
            # TODO
            axisNeedsAdjusting = (centers[i] / wrapPoints) &gt; 1
            for j in np.where(axisNeedsAdjusting)[0]:
                centers[i][j] -= wrapPoints[j]

    else:
        for i in range(numLabels):
            indices = np.where(labels == i)
            # Weighted average
            centers[i] = np.average(np.array(points)[indices], weights=individualWeights[indices], axis=0)
            weights[i] = np.sum(individualWeights[indices]) / np.sum(individualWeights)

    order = np.argsort(weights)[::-1]
    centers = centers[order]
    weights = weights[order]
    
    if return_weights:
        return centers, weights
        
    return centers</code></pre>
</details>
</dd>
<dt id="pepe.topology.Clustering.spatialClusterLabels"><code class="name flex">
<span>def <span class="ident">spatialClusterLabels</span></span>(<span>points, l=0.001, randomize=False, wrapPoints=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Partition a set of points in clusters, and return the
cluster label for each point.</p>
<p>Method is very simplistic: the neighbors (points within
a threshold distance) of a point are added to the same
cluster, and the process is repeated until no points
remain. This means that the size of clusters can be
larger than this distance threshold (eg. think of a
chain of points).</p>
<h2 id="usage">Usage</h2>
<p>The partitioning process is done by iterating through all
of the provided points, and identifying their neighbors. As
such, this process can vary based on the order the points are
provided in. There are two different ways to deal with this
while still maintaining reproducible results.</p>
<p>First, you can order the points in some meaningful way, with
the more important (whatever that means for your case) points
coming first. This should be done before calling this partitioning
method. Second, you can use the <code>randomize=True</code> kwarg, and rely
on the fact that this should lead to a statistically sound
calculation.</p>
<p>As an example, consider identifying clusters of points above some
threshold (whether in brightness, <span><span class="MathJax_Preview">G^2</span><script type="math/tex">G^2</script></span>, or whatever else) in
an image. For the first approach, you might order the points by the
magnitude of the parameter you are thresholding with respect to, since
eg. it could be assumed that very bright points are more important
than points that are just barely above the threshold. For the second
approach, you might perform the clustering process M times to get
a statistical ensemble, and then resolve the individual partitionings
into a single combined one.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>points</code></strong> :&ensp;<code>numpy.ndarray[N,d]</code></dt>
<dd>Array of N points in d-dimensions</dd>
<dt><strong><code>l</code></strong> :&ensp;<code>float</code></dt>
<dd>Distance threshold to consider two points as being in the
same cluster. Given as fraction of the total system size.</dd>
<dt><strong><code>randomize</code></strong> :&ensp;<code>bool</code></dt>
<dd>The clustering processes is dependent on the order of
the points; if <code>randomize=True</code>, the provided array will
be indexed in a random order, otherwise it will be accessed
exactly as provided.</dd>
<dt><strong><code>wrapPoints</code></strong> :&ensp;<code>numpy.ndarray[d]</code> or <code>float</code> or <code>None</code></dt>
<dd>
<p>If the space is periodic, the size of each dimension. If
a single value is given, this will be used for all dimensions.</p>
<p>If None, no periodicity is assumed.</p>
<p>Can have a mix of periodic and non-periodic dimensions,
eg. spherical coordinates should have:
<code>wrapPoints=[None, 2*np.pi, np.pi]</code></p>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>labels</code></strong> :&ensp;<code>numpy.ndarray[N]</code></dt>
<dd>Array of N labels (integers) denoting cluster
assignment. Total number of clusters will be <code>max(labels)+1</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def spatialClusterLabels(points, l=.001, randomize=False, wrapPoints=None):
    &#34;&#34;&#34;
    Partition a set of points in clusters, and return the
    cluster label for each point.

    Method is very simplistic: the neighbors (points within
    a threshold distance) of a point are added to the same
    cluster, and the process is repeated until no points
    remain. This means that the size of clusters can be
    larger than this distance threshold (eg. think of a
    chain of points).

    Usage
    -----
    The partitioning process is done by iterating through all
    of the provided points, and identifying their neighbors. As
    such, this process can vary based on the order the points are
    provided in. There are two different ways to deal with this
    while still maintaining reproducible results.

    First, you can order the points in some meaningful way, with
    the more important (whatever that means for your case) points
    coming first. This should be done before calling this partitioning
    method. Second, you can use the `randomize=True` kwarg, and rely
    on the fact that this should lead to a statistically sound
    calculation.

    As an example, consider identifying clusters of points above some
    threshold (whether in brightness, \(G^2\), or whatever else) in
    an image. For the first approach, you might order the points by the
    magnitude of the parameter you are thresholding with respect to, since
    eg. it could be assumed that very bright points are more important
    than points that are just barely above the threshold. For the second
    approach, you might perform the clustering process M times to get
    a statistical ensemble, and then resolve the individual partitionings
    into a single combined one.

    Parameters
    ----------
    points : numpy.ndarray[N,d]
        Array of N points in d-dimensions

    l : float
        Distance threshold to consider two points as being in the
        same cluster. Given as fraction of the total system size.

    randomize : bool
        The clustering processes is dependent on the order of
        the points; if `randomize=True`, the provided array will
        be indexed in a random order, otherwise it will be accessed
        exactly as provided.

    wrapPoints : numpy.ndarray[d] or float or None
        If the space is periodic, the size of each dimension. If
        a single value is given, this will be used for all dimensions.

        If None, no periodicity is assumed.

        Can have a mix of periodic and non-periodic dimensions,
        eg. spherical coordinates should have:
            `wrapPoints=[None, 2*np.pi, np.pi]`
        
    Returns
    -------
    labels : numpy.ndarray[N]
        Array of N labels (integers) denoting cluster
        assignment. Total number of clusters will be `max(labels)+1`.
    &#34;&#34;&#34;
    d = np.shape(points)[-1]
    
    systemLengthScale = np.sqrt(np.sum([(np.max(points[:,i]) - np.min(points[:,i]))**2 for i in range(d)]))
    threshold = l*systemLengthScale
   
    # Generate a kd-tree
    # If we have a periodic space, we need to clean and pass that
    # information to the kd tree
    if hasattr(wrapPoints, &#39;__iter__&#39;):
        assert len(wrapPoints) == d, f&#39;Wrap dimensions ({len(wrapPoints)}) do not match the dimension of the data ({d})!&#39;

        boxSize = np.array([wrapPoints[i] if wrapPoints[i] is not None else np.max(points[:,i])*10 for i in range(d)])
        kdTree = KDTree(points, boxsize=boxSize)

    elif wrapPoints is not None:
        boxSize = np.repeat(wrapPoints, d)
        kdTree = KDTree(points, boxsize=boxSize)
    
    else:
        kdTree = KDTree(points)

    pointsList = points.tolist()

    randomOrder = np.arange(len(pointsList))

    if randomize:
        np.random.shuffle(randomOrder)
    
    labels = np.zeros(len(pointsList)) - 1
    labelsToMerge = []
    
    i = 0
    
    while len(np.where(labels == -1)[0]) &gt; 0:
        # Grab a point, if it doesn&#39;t have a group already, create a new one
        if labels[randomOrder[i]] == -1:
            labels[randomOrder[i]] = np.max(labels)+1
        p = pointsList[randomOrder[i]]

        # Find its neighbors
        neighbors = kdTree.query_ball_point(p, r=threshold)

        # neighorLabels = [labels[n] for n in neighors]
        # uniqueNeighborLabels = np.unique(neighborLabels)
        # if len(uniqueNeighborLabels) == 1:
        #     # If all are unlabeled
        #     if uniqueNeighborLabels[0] == -1:
        #         # Create a new group
        #         labels[randomOrder[i]] = np.max(labels)+1

        #     # All are already in another group
        #     else:
        #         # Assign this point to that group as well
        #         labels[randomOrder[i]] = uniqueNeighborLabels[0]
        
        # Assign all of them to be the same group
        for index in neighbors:
            if index == randomOrder[i]:
                continue
                
            # If they already have a label, we will eventually want to merge the labels
            if labels[index] &gt;= 0 and labels[index] != labels[randomOrder[i]]:
                # See if this is already in a merge group
                inGroup = False
                for j in range(len(labelsToMerge)):
                    # If it is already going to be merged, add the
                    # new label to this group
                    if labels[index] in labelsToMerge[j]:
                        inGroup = True
                        # If the new label is not in the merge group, add it
                        if not labels[randomOrder[i]] in labelsToMerge[j]:
                            labelsToMerge[j].append(labels[randomOrder[i]])
                            
                        break
                # If we aren&#39;t in a merge group, we should create
                # a new one
                if not inGroup:
                    labelsToMerge.append([labels[index], labels[randomOrder[i]]])
                    
            elif labels[index] == -1:
                labels[index] = labels[randomOrder[i]]
            
        i += 1

    mergedLabels = np.zeros_like(labels) - 1
    
    # Now we have to sort out merged clusters
    labelSets = []
    for i in range(int(np.max(labels))+1):
        # Generate a list of all of the labels that are identified together
        # including this value of i
        allLabels = [i]
        for j in range(len(labelsToMerge)):
            if i in labelsToMerge[j]:
                allLabels += labelsToMerge[j]

        # sort so that way we can do a unique check to remove
        # duplicates
        allLabels = sorted(np.unique(allLabels))
        # Python may automatically collapse the list if it is of length 1,
        # which we don&#39;t want.
        labelSets.append([allLabels] if len(allLabels) == 1 else allLabels)

    # Remove duplicate sets, creating disjoint sets of labels
    uniqueSets = np.unique(np.array(labelSets, list))

    # If there are no overlaps, then this above operation will
    # flatten the array to be one dimensional. We can&#39;t do anything
    # about that, except to check if it is the case. The good news is
    # that if this is the case, then we already have disjoint sets
    # and we can just immediately return our label array
    if len(np.shape(uniqueSets)) == 1:
        return labels

    # Relabel things with the new disjoint sets
    mergedLabels = np.zeros_like(labels)

    # TODO: Probably a much better way to do this
    for i in range(len(pointsList)):
        for j in range(len(uniqueSets)):
            if labels[i] in uniqueSets[j]:
                mergedLabels[i] = j
                break

    return mergedLabels</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pepe.topology" href="index.html">pepe.topology</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pepe.topology.Clustering.spatialClusterCenters" href="#pepe.topology.Clustering.spatialClusterCenters">spatialClusterCenters</a></code></li>
<li><code><a title="pepe.topology.Clustering.spatialClusterLabels" href="#pepe.topology.Clustering.spatialClusterLabels">spatialClusterLabels</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>